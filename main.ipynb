{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: torch in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leon1\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\leon1\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: fsspec in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.4.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\leon1\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.12.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#Dependency setup\n",
    "!python -m pip install numpy matplotlib torch sklearn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import torch\n",
    "import partition_scripts\n",
    "from neural_nets import get_parameters, set_parameters, train, test, VGG7, Net, centralized_training\n",
    "\n",
    "DATA_STORE = {\n",
    "    \"CIFAR10_IID\": None,\n",
    "    \"CIFAR10_NonIID\": None,\n",
    "    \"CIFAR100_IID\": None,\n",
    "    \"CIFAR100_NonIID\": None,\n",
    "    \"FedFaces_IID\": None,\n",
    "    \"FedFaces_NonIID\": None,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority class count: 9266\n",
      "Shape CIFAR IID: (64, 64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (unsigned char) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     DATA_STORE[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFedFaces\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m partition_scripts\u001b[38;5;241m.\u001b[39mpartition_FedFaces_IID(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     20\u001b[0m     dataloaders, valloaders, testloaders \u001b[38;5;241m=\u001b[39m DATA_STORE[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFedFaces\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mcentralized_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leon1\\Documents\\Research Repo\\Experiments\\Ethnicity FL paper\\neural_nets.py:122\u001b[0m, in \u001b[0;36mcentralized_training\u001b[1;34m(trainloader, valloader, testloader, DEVICE, epochs)\u001b[0m\n\u001b[0;32m    119\u001b[0m net \u001b[38;5;241m=\u001b[39m Net()\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 122\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     loss, accuracy \u001b[38;5;241m=\u001b[39m test(net, valloader)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: validation loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\leon1\\Documents\\Research Repo\\Experiments\\Ethnicity FL paper\\neural_nets.py:84\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, trainloader, epochs, verbose, DEVICE)\u001b[0m\n\u001b[0;32m     82\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(DEVICE), labels\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     83\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 84\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# print(outputs[0])\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# print(labels[0])\u001b[39;00m\n\u001b[0;32m     87\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leon1\\Documents\\Research Repo\\Experiments\\Ethnicity FL paper\\neural_nets.py:65\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 65\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     66\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# x = self.pool(F.relu(self.conv3(x)))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "experiments = [\"CIFAR10\", \"CIFAR100\", \"CelebA\", \"FedFaces\"]\n",
    "curr = experiments[3]\n",
    "epochs = 20\n",
    "\n",
    "match curr:\n",
    "    case \"CIFAR10\":\n",
    "        DATA_STORE[\"CIFAR10\"] = partition_scripts.partition_CIFAR_IID(2)\n",
    "        dataloaders, valloaders, testloaders = DATA_STORE[\"CIFAR10\"]\n",
    "        centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], testloader=testloaders, epochs=epochs)\n",
    "    case \"CIFAR100\":\n",
    "        DATA_STORE[\"CIFAR100\"] = partition_scripts.partition_CIFAR_IID(2, \"CIFAR100\")\n",
    "        dataloaders, valloaders, testloaders = DATA_STORE[\"CIFAR100\"]\n",
    "        centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], testloader=testloaders, epochs=epochs)\n",
    "    case \"CelebA\":\n",
    "        DATA_STORE[\"CelebA\"] = partition_scripts.partition_CelebA_IID(2)\n",
    "        dataloaders, valloaders, testloaders = DATA_STORE[\"CelebA\"]\n",
    "        centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], testloader=testloaders, epochs=epochs)\n",
    "    case \"FedFaces\":\n",
    "        DATA_STORE[\"FedFaces\"] = partition_scripts.partition_FedFaces_IID(2)\n",
    "        dataloaders, valloaders, testloaders = DATA_STORE[\"FedFaces\"]\n",
    "        centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], testloader=testloaders, epochs=epochs)\n",
    "    case _:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a FLWR environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.2.0+cpu and Flower 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import flwr.server.strategy as strategy\n",
    "\n",
    "from flwr.common import Metrics\n",
    "\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "fl.common.logger.configure(identifier=\"FL Paper Experiment\", filename=f\"log_FLWR_{today.timestamp()}.txt\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")\n",
    "\n",
    "NUM_CLIENTS = 20\n",
    "TRAINING_ROUNDS = 50\n",
    "\n",
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll set up the Client configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from logging import DEBUG, INFO\n",
    "from flwr.common.logger import log\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader, cid):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.cid = cid\n",
    "        self.round = 0\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        # Return the current local parameters\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Train the local model after updating it with the given parameters\n",
    "        # Return the parameters from the newly trained model, the length\n",
    "        # of the training data, and a dict (empty in this case)\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs = 1)\n",
    "        self.round+=1\n",
    "        log(DEBUG, f\"Client {self.cid} in round {self.round}\")\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Perform the evaluation of the model after updating it with the given\n",
    "        # parameters. Returns the loss as a float, the length of the validation\n",
    "        # data, and a dict containing the accuracy\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return loss, len(self.valloader), {'accuracy': float(accuracy)}\n",
    "\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, setting up the strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FedAvg on CIFAR ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "fedAvg = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,  \n",
    "    fraction_evaluate=0.5,  \n",
    "    min_fit_clients=1,  \n",
    "    min_evaluate_clients=1, \n",
    "    min_available_clients=1,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "\n",
    "# A couple of client_fns for using with Flower, one for each dataset experiment\n",
    "def client_fn_CIFAR10_IID(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Create model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    trainloaders, valloaders,_ =  DATA_STORE[\"CIFAR10_IID\"]\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader, cid).to_client()\n",
    "\n",
    "def client_fn_CIFAR10_nonIID(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Create model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    trainloaders, valloaders,_ =  DATA_STORE[\"CIFAR10_NonIID\"]\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader, cid).to_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick run to check if Flower is working ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start simulation\n",
    "run = False\n",
    "if (run):\n",
    "    fl.simulation.start_simulation(\n",
    "        client_fn=client_fn_CIFAR10_IID,\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=2),\n",
    "        strategy=fedAvg,\n",
    "        client_resources=client_resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FedExperiment Class ###\n",
    "Ok, so now i'll encapsulate this code to reuse with different strategies and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedExperiment():\n",
    "\n",
    "    def __init__(self, client_fn,strategy, name=\"New experiment\"):\n",
    "        self.client_fn = client_fn\n",
    "        self.strategy = strategy\n",
    "        self.name = name\n",
    "\n",
    "    def simulate_FL(self, rounds=1):\n",
    "        log(INFO, \"\\n\" + 10 * \"========\" + \"\\n\" + self.name + \" has started\\n\" + 10 * \"========\"  )\n",
    "        metrics = fl.simulation.start_simulation(\n",
    "                            client_fn=self.client_fn,\n",
    "                            num_clients=NUM_CLIENTS,\n",
    "                            config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "                            strategy=self.strategy,\n",
    "                            client_resources=client_resources,\n",
    "                        )\n",
    "        log(INFO, \"\\n\" + 10 * \"========\" + \"\\n\" + self.name + \" has ended\\n\" + 10 * \"========\"  )\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-02-23 13:45:51,322 | 527930960.py:9 | \n",
      "================================================================================\n",
      "CIFAR 10 - IID Distribution has started\n",
      "================================================================================\n",
      "INFO flwr 2024-02-23 13:45:51,322 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape CIFAR IID: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 13:45:55,826\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-02-23 13:45:57,577 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 12.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 2822028902.0, 'memory': 5644057806.0, 'node:__internal_head__': 1.0}\n",
      "INFO flwr 2024-02-23 13:45:57,577 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-02-23 13:45:57,577 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 0}\n",
      "INFO flwr 2024-02-23 13:45:57,577 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 6 actors\n",
      "INFO flwr 2024-02-23 13:45:57,577 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-02-23 13:45:57,577 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-02-23 13:46:01,410 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-02-23 13:46:01,411 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-02-23 13:46:01,412 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-02-23 13:46:01,412 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=4428)\u001b[0m DEBUG flwr 2024-02-23 13:46:51,863 | 3002787810.py:26 | Client 7 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=5420)\u001b[0m DEBUG flwr 2024-02-23 13:47:02,898 | 3002787810.py:26 | Client 9 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=13584)\u001b[0m DEBUG flwr 2024-02-23 13:47:04,601 | 3002787810.py:26 | Client 3 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=8640)\u001b[0m DEBUG flwr 2024-02-23 13:47:10,742 | 3002787810.py:26 | Client 0 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=4428)\u001b[0m DEBUG flwr 2024-02-23 13:47:49,869 | 3002787810.py:26 | Client 5 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=5420)\u001b[0m DEBUG flwr 2024-02-23 13:47:58,264 | 3002787810.py:26 | Client 1 in round 1\n",
      "DEBUG flwr 2024-02-23 13:48:00,096 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2024-02-23 13:48:00,195 | fedavg.py:250 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-02-23 13:48:00,195 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-02-23 13:48:06,066 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 13:48:06,066 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=8640)\u001b[0m DEBUG flwr 2024-02-23 13:49:17,058 | 3002787810.py:26 | Client 6 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10668)\u001b[0m DEBUG flwr 2024-02-23 13:49:24,362 | 3002787810.py:26 | Client 5 in round 1\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=8640)\u001b[0m DEBUG flwr 2024-02-23 13:50:21,628 | 3002787810.py:26 | Client 4 in round 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-02-23 13:50:25,630 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 13:50:25,739 | server.py:173 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-02-23 13:50:32,954 | server.py:187 | evaluate_round 2 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 13:50:32,954 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=13584)\u001b[0m DEBUG flwr 2024-02-23 13:51:50,053 | 3002787810.py:26 | Client 9 in round 1\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=5420)\u001b[0m DEBUG flwr 2024-02-23 13:51:55,688 | 3002787810.py:26 | Client 2 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=13584)\u001b[0m DEBUG flwr 2024-02-23 13:52:56,888 | 3002787810.py:26 | Client 8 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-02-23 13:53:01,509 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 13:53:01,608 | server.py:173 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-02-23 13:53:08,614 | server.py:187 | evaluate_round 3 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 13:53:08,614 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10668)\u001b[0m DEBUG flwr 2024-02-23 13:54:27,188 | 3002787810.py:26 | Client 2 in round 1\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=8640)\u001b[0m DEBUG flwr 2024-02-23 13:54:32,983 | 3002787810.py:26 | Client 5 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10668)\u001b[0m DEBUG flwr 2024-02-23 13:55:33,001 | 3002787810.py:26 | Client 4 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-02-23 13:55:37,586 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 13:55:37,686 | server.py:173 | evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-02-23 13:55:43,891 | server.py:187 | evaluate_round 4 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 13:55:43,891 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=11916)\u001b[0m DEBUG flwr 2024-02-23 13:57:03,263 | 3002787810.py:26 | Client 8 in round 1\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=4428)\u001b[0m DEBUG flwr 2024-02-23 13:57:09,891 | 3002787810.py:26 | Client 0 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=11916)\u001b[0m DEBUG flwr 2024-02-23 13:58:10,894 | 3002787810.py:26 | Client 7 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-02-23 13:58:15,952 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=4428)\u001b[0m DEBUG flwr 2024-02-23 13:58:15,918 | 3002787810.py:26 | Client 3 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-02-23 13:58:16,067 | server.py:173 | evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-02-23 13:58:23,097 | server.py:187 | evaluate_round 5 received 5 results and 0 failures\n",
      "INFO flwr 2024-02-23 13:58:23,097 | server.py:153 | FL finished in 741.6855394999993\n",
      "INFO flwr 2024-02-23 13:58:23,097 | app.py:226 | app_fit: losses_distributed [(1, 0.03562954177856446), (2, 0.025969836235046385), (3, 0.02311199498176575), (4, 0.021931134033203126), (5, 0.020923221397399903)]\n",
      "INFO flwr 2024-02-23 13:58:23,104 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-02-23 13:58:23,105 | app.py:228 | app_fit: metrics_distributed {'accuracy': [(1, 0.1348), (2, 0.40599999999999997), (3, 0.454), (4, 0.4932), (5, 0.5244000000000001)]}\n",
      "INFO flwr 2024-02-23 13:58:23,107 | app.py:229 | app_fit: losses_centralized []\n",
      "INFO flwr 2024-02-23 13:58:23,108 | app.py:230 | app_fit: metrics_centralized {}\n",
      "INFO flwr 2024-02-23 13:58:23,115 | 527930960.py:17 | \n",
      "================================================================================\n",
      "CIFAR 10 - IID Distribution has ended\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History (loss, distributed):\n",
      "\tround 1: 0.03562954177856446\n",
      "\tround 2: 0.025969836235046385\n",
      "\tround 3: 0.02311199498176575\n",
      "\tround 4: 0.021931134033203126\n",
      "\tround 5: 0.020923221397399903\n",
      "History (metrics, distributed, evaluate):\n",
      "{'accuracy': [(1, 0.1348), (2, 0.40599999999999997), (3, 0.454), (4, 0.4932), (5, 0.5244000000000001)]}\n"
     ]
    }
   ],
   "source": [
    "DATA_STORE[\"CIFAR10_IID\"]= partition_scripts.partition_CIFAR_IID(NUM_CLIENTS, \"CIFAR10\")\n",
    "exp_CIFAR10_IID = FedExperiment(client_fn=client_fn_CIFAR10_IID, strategy=fedAvg, name=\"CIFAR 10 - IID Distribution\")\n",
    "metrics = exp_CIFAR10_IID.simulate_FL(rounds=5)\n",
    "print(metrics)\n",
    "DATA_STORE[\"CIFAR10_IID\"]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape CIFAR nonIID: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-02-23 14:24:39,699 | 527930960.py:9 | \n",
      "================================================================================\n",
      "CIFAR 10 - nonIID Distribution has started\n",
      "================================================================================\n",
      "INFO flwr 2024-02-23 14:24:39,699 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "2024-02-23 14:24:45,001\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-02-23 14:24:46,803 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 5832088782.0, 'object_store_memory': 2916044390.0, 'node:127.0.0.1': 1.0, 'CPU': 12.0, 'node:__internal_head__': 1.0}\n",
      "INFO flwr 2024-02-23 14:24:46,818 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-02-23 14:24:46,819 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0}\n",
      "INFO flwr 2024-02-23 14:24:46,819 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 12 actors\n",
      "INFO flwr 2024-02-23 14:24:46,819 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-02-23 14:24:46,819 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-02-23 14:24:52,607 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-02-23 14:24:52,607 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-02-23 14:24:52,617 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-02-23 14:24:52,618 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=9840)\u001b[0m DEBUG flwr 2024-02-23 14:26:17,561 | 3002787810.py:26 | Client 7 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7540)\u001b[0m DEBUG flwr 2024-02-23 14:26:55,225 | 3002787810.py:26 | Client 0 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=13024)\u001b[0m DEBUG flwr 2024-02-23 14:27:21,229 | 3002787810.py:26 | Client 2 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=4828)\u001b[0m DEBUG flwr 2024-02-23 14:27:26,333 | 3002787810.py:26 | Client 6 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=5996)\u001b[0m DEBUG flwr 2024-02-23 14:27:32,839 | 3002787810.py:26 | Client 1 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1160)\u001b[0m DEBUG flwr 2024-02-23 14:27:35,274 | 3002787810.py:26 | Client 3 in round 1\n",
      "DEBUG flwr 2024-02-23 14:27:45,649 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=16952)\u001b[0m DEBUG flwr 2024-02-23 14:27:45,616 | 3002787810.py:26 | Client 8 in round 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "WARNING flwr 2024-02-23 14:27:45,755 | fedavg.py:250 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-02-23 14:27:45,755 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-02-23 14:28:08,633 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 14:28:08,633 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2024-02-23 14:29:26,537 C 7588 12368] (raylet.exe) dlmalloc.cc:129:  Check failed: *handle != nullptr CreateFileMapping() failed. GetLastError() = 1450\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m recalloc\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m BaseThreadInitThunk\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m RtlUserThreadStart\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "2024-02-23 14:29:41,188\tWARNING worker.py:2037 -- The node with node id: c1287d6e1710f87a8e1158cd3b0b2595374734f26eac2826539b9c86 and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, preempted node, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n",
      "Exception in thread Thread-52:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1358, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flwr\\simulation\\app.py\", line 276, in update_resources\n",
      "    num_max_actors = pool_size_from_resources(client_resources)\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 155, in pool_size_from_resources\n",
      "    num_cpus,\n",
      "UnboundLocalError: local variable 'num_cpus' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "DATA_STORE[\"CIFAR10_NonIID\"] = partition_scripts.partition_CIFAR_nonIID(NUM_CLIENTS)\n",
    "exp_CIFAR10_nonIID = FedExperiment(client_fn=client_fn_CIFAR10_nonIID, strategy=fedAvg, name=\"CIFAR 10 - nonIID Distribution\")\n",
    "metrics = exp_CIFAR10_nonIID.simulate_FL(rounds=5)\n",
    "print(metrics)\n",
    "DATA_STORE[\"CIFAR10_NonIID\"] = partition_scripts.partition_CIFAR_nonIID(NUM_CLIENTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
