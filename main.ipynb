{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting intel-extension-for-pytorch==2.1.10+xpu\n",
      "  Downloading https://github.com/Nuullll/intel-extension-for-pytorch/releases/download/v2.1.10%2Bxpu/intel_extension_for_pytorch-2.1.10+xpu-cp310-cp310-win_amd64.whl (367.2 MB)\n",
      "Requirement already satisfied: psutil in c:\\users\\leon1\\appdata\\roaming\\python\\python310\\site-packages (from intel-extension-for-pytorch==2.1.10+xpu) (5.9.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\leon1\\appdata\\roaming\\python\\python310\\site-packages (from intel-extension-for-pytorch==2.1.10+xpu) (23.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from intel-extension-for-pytorch==2.1.10+xpu) (1.10.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from intel-extension-for-pytorch==2.1.10+xpu) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\leon1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic->intel-extension-for-pytorch==2.1.10+xpu) (4.9.0)\n",
      "Installing collected packages: intel-extension-for-pytorch\n",
      "Successfully installed intel-extension-for-pytorch-2.1.10+xpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install https://github.com/Nuullll/intel-extension-for-pytorch/releases/download/v2.1.10%2Bxpu/intel_extension_for_pytorch-2.1.10+xpu-cp310-cp310-win_amd64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import datetime\n",
    "import partition_scripts\n",
    "from neural_nets import get_parameters, set_parameters, train, test, Net, centralized_training, VGG7\n",
    "\n",
    "\n",
    "DATA_STORE = {\n",
    "    \"CIFAR10_IID\": None,\n",
    "    \"CIFAR10_NonIID\": None,\n",
    "    \"CIFAR100_IID\": None,\n",
    "    \"CIFAR100_NonIID\": None,\n",
    "    \"FedFaces_IID\": None,\n",
    "    \"FedFaces_NonIID\": None,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"CIFAR10\", \"CIFAR100\", \"CelebA\", \"FedFaces\"]\n",
    "epochs = 400\n",
    "\n",
    "def run_centralized(experiment):\n",
    "    match experiment:\n",
    "        case \"CIFAR10\":\n",
    "            DATA_STORE[\"CIFAR10\"] = partition_scripts.partition_CIFAR_IID(2)\n",
    "            dataloaders, valloaders, testloaders = DATA_STORE[\"CIFAR10\"]\n",
    "            net = VGG7(classes=10)\n",
    "            centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], testloader=testloaders, net=net, epochs=epochs, classes=10, DEVICE=\"cpu\")\n",
    "        case \"CIFAR100\":\n",
    "            DATA_STORE[\"CIFAR100\"] = partition_scripts.partition_CIFAR_IID(2, \"CIFAR100\")\n",
    "            dataloaders, valloaders, testloaders = DATA_STORE[\"CIFAR100\"]\n",
    "            net = VGG7(classes=100)\n",
    "            centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], testloader=testloaders, epochs=epochs, classes=100)\n",
    "        case \"CelebA\":\n",
    "            DATA_STORE[\"CelebA\"] = partition_scripts.partition_CelebA_IID(2)\n",
    "            dataloaders, valloaders, testloaders = DATA_STORE[\"CelebA\"]\n",
    "            net = VGG7(classes=2, shape=(64, 64))\n",
    "            centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], testloader=testloaders, epochs=epochs, net=net)\n",
    "        case \"FedFaces\":\n",
    "            DATA_STORE[\"FedFaces\"] = partition_scripts.partition_FedFaces_IID(2)\n",
    "            dataloaders, valloaders, testloaders = DATA_STORE[\"FedFaces\"]\n",
    "            net = VGG7(classes=4, shape=(64,64))\n",
    "            centralized_training(trainloader=dataloaders[0], valloader=valloaders[0], net=net, testloader=testloaders, epochs=epochs, classes=3)\n",
    "        case _:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: validation loss 0.02746488166809082, accuracy 0.344\n",
      "Epoch 2: validation loss 0.024026091976165773, accuracy 0.4264\n",
      "Epoch 3: validation loss 0.022680024433135985, accuracy 0.4616\n",
      "Epoch 4: validation loss 0.021432508878707887, accuracy 0.52056\n",
      "Epoch 5: validation loss 0.020805716314315797, accuracy 0.538\n",
      "Epoch 6: validation loss 0.018972875962257385, accuracy 0.59696\n",
      "Epoch 7: validation loss 0.01824114131450653, accuracy 0.59728\n",
      "Epoch 8: validation loss 0.01795127950668335, accuracy 0.61104\n",
      "Epoch 9: validation loss 0.016901257915496827, accuracy 0.61424\n",
      "Epoch 10: validation loss 0.017062027134895325, accuracy 0.6008\n",
      "Epoch 11: validation loss 0.017588741207122803, accuracy 0.60216\n",
      "Epoch 12: validation loss 0.01673342333316803, accuracy 0.63192\n",
      "Epoch 13: validation loss 0.014955187039375305, accuracy 0.67016\n",
      "Epoch 14: validation loss 0.017368359627723692, accuracy 0.62392\n",
      "Epoch 15: validation loss 0.015764442863464356, accuracy 0.66288\n",
      "Epoch 16: validation loss 0.01915823311328888, accuracy 0.632\n",
      "Epoch 17: validation loss 0.015699765655994416, accuracy 0.6936\n",
      "Epoch 18: validation loss 0.01535943480014801, accuracy 0.6824\n",
      "Epoch 19: validation loss 0.016688665928840638, accuracy 0.6656\n",
      "Epoch 20: validation loss 0.018261393826007843, accuracy 0.6864\n",
      "Epoch 21: validation loss 0.019215103297233582, accuracy 0.6656\n",
      "Epoch 22: validation loss 0.02339430031299591, accuracy 0.656\n",
      "Epoch 23: validation loss 0.01872192577838898, accuracy 0.70568\n",
      "Epoch 24: validation loss 0.022322290530204774, accuracy 0.68912\n",
      "Epoch 25: validation loss 0.016464261751174925, accuracy 0.70584\n",
      "Epoch 26: validation loss 0.020992074213027952, accuracy 0.70944\n",
      "Epoch 27: validation loss 0.023175941460132597, accuracy 0.70648\n",
      "Epoch 28: validation loss 0.023991784353256225, accuracy 0.66872\n",
      "Epoch 29: validation loss 0.02877126986503601, accuracy 0.7088\n",
      "Epoch 30: validation loss 0.02272891776561737, accuracy 0.6964\n",
      "Epoch 31: validation loss 0.03533421339035034, accuracy 0.70344\n",
      "Epoch 32: validation loss 0.02799453375339508, accuracy 0.70352\n",
      "Epoch 33: validation loss 0.030604841017723084, accuracy 0.71104\n",
      "Epoch 34: validation loss 0.027406132984161377, accuracy 0.70664\n",
      "Epoch 35: validation loss 0.045865431547164916, accuracy 0.7096\n",
      "Epoch 36: validation loss 0.03535591302871704, accuracy 0.70168\n",
      "Epoch 37: validation loss 0.019735082335472106, accuracy 0.6772\n",
      "Epoch 38: validation loss 0.0224406010723114, accuracy 0.69976\n",
      "Epoch 39: validation loss 0.02688188014984131, accuracy 0.70928\n",
      "Epoch 40: validation loss 0.023052883052825927, accuracy 0.70808\n",
      "Epoch 41: validation loss 0.02569272873401642, accuracy 0.7124\n",
      "Epoch 42: validation loss 0.02915865831375122, accuracy 0.60416\n",
      "Epoch 43: validation loss 0.04074507887840271, accuracy 0.69864\n",
      "Epoch 44: validation loss 0.03423088764667511, accuracy 0.71664\n",
      "Epoch 45: validation loss 0.027981344022750855, accuracy 0.70944\n",
      "Epoch 46: validation loss 0.02573194568157196, accuracy 0.69696\n",
      "Epoch 47: validation loss 0.04111100776195526, accuracy 0.66184\n",
      "Epoch 48: validation loss 0.028356008701324462, accuracy 0.69256\n",
      "Epoch 49: validation loss 0.028951926684379577, accuracy 0.70832\n",
      "Epoch 50: validation loss 0.034483025822639464, accuracy 0.7128\n",
      "Epoch 51: validation loss 0.0372945761013031, accuracy 0.71952\n",
      "Epoch 52: validation loss 0.019612857189178465, accuracy 0.69488\n",
      "Epoch 53: validation loss 0.033326785593032836, accuracy 0.69728\n",
      "Epoch 54: validation loss 0.026898713326454163, accuracy 0.67432\n",
      "Epoch 55: validation loss 0.03593510550260544, accuracy 0.716\n",
      "Epoch 56: validation loss 0.05423999507427216, accuracy 0.70096\n",
      "Epoch 57: validation loss 0.04756321719646454, accuracy 0.70544\n",
      "Epoch 58: validation loss 0.055163585147857665, accuracy 0.66832\n",
      "Epoch 59: validation loss 0.03586034646987915, accuracy 0.6984\n",
      "Epoch 60: validation loss 0.030013264303207398, accuracy 0.6996\n",
      "Epoch 61: validation loss 0.025024987149238585, accuracy 0.70272\n",
      "Epoch 62: validation loss 0.03940859659910202, accuracy 0.7224\n",
      "Epoch 63: validation loss 0.03310055303096771, accuracy 0.6748\n",
      "Epoch 64: validation loss 0.03193860951423645, accuracy 0.69448\n",
      "Epoch 65: validation loss 0.03862968715667724, accuracy 0.66696\n",
      "Epoch 66: validation loss 0.044320124335289, accuracy 0.70816\n",
      "Epoch 67: validation loss 0.056513175129890444, accuracy 0.69752\n",
      "Epoch 68: validation loss 0.04165293228626251, accuracy 0.7012\n",
      "Epoch 69: validation loss 0.05385626194238663, accuracy 0.70608\n",
      "Epoch 70: validation loss 0.04169195670127868, accuracy 0.6992\n",
      "Epoch 71: validation loss 0.036690467200279235, accuracy 0.70216\n",
      "Epoch 72: validation loss 0.030581545128822326, accuracy 0.71128\n",
      "Epoch 73: validation loss 0.03042877227783203, accuracy 0.6976\n",
      "Epoch 74: validation loss 0.05847258150100708, accuracy 0.698\n",
      "Epoch 75: validation loss 0.03683352829933167, accuracy 0.69344\n",
      "Epoch 76: validation loss 0.03805898781776428, accuracy 0.70984\n",
      "Epoch 77: validation loss 0.034315751030445096, accuracy 0.69664\n",
      "Epoch 78: validation loss 0.045680130195617674, accuracy 0.70808\n",
      "Epoch 79: validation loss 0.03215036823272705, accuracy 0.68856\n",
      "Epoch 80: validation loss 0.02955575180053711, accuracy 0.65968\n",
      "Epoch 81: validation loss 0.03156841114997864, accuracy 0.66928\n",
      "Epoch 82: validation loss 0.07701373957633972, accuracy 0.706\n",
      "Epoch 83: validation loss 0.057990776562690735, accuracy 0.6992\n",
      "Epoch 84: validation loss 0.07420697653770447, accuracy 0.61696\n",
      "Epoch 85: validation loss 0.03163784477710724, accuracy 0.69544\n",
      "Epoch 86: validation loss 0.03826850220680237, accuracy 0.69552\n",
      "Epoch 87: validation loss 0.035595613112449645, accuracy 0.70416\n",
      "Epoch 88: validation loss 0.04838297779083252, accuracy 0.69664\n",
      "Epoch 89: validation loss 0.054730123105049135, accuracy 0.69952\n",
      "Epoch 90: validation loss 0.048500764493942264, accuracy 0.67456\n",
      "Epoch 91: validation loss 0.041789555087089536, accuracy 0.68432\n",
      "Epoch 92: validation loss 0.03456778693675995, accuracy 0.66144\n",
      "Epoch 93: validation loss 0.03709025827884674, accuracy 0.69528\n",
      "Epoch 94: validation loss 0.05844115225315094, accuracy 0.70696\n",
      "Epoch 95: validation loss 0.056335431509017944, accuracy 0.68296\n",
      "Epoch 96: validation loss 0.048477466492652894, accuracy 0.70328\n",
      "Epoch 97: validation loss 0.036584358615875244, accuracy 0.7004\n",
      "Epoch 98: validation loss 0.07981514525413513, accuracy 0.66496\n",
      "Epoch 99: validation loss 0.05669431600093842, accuracy 0.70528\n",
      "Epoch 100: validation loss 0.04928680610656738, accuracy 0.69024\n",
      "Epoch 101: validation loss 0.0304994687128067, accuracy 0.66984\n",
      "Epoch 102: validation loss 0.061454400839805606, accuracy 0.68736\n",
      "Epoch 103: validation loss 0.0641556684589386, accuracy 0.68672\n",
      "Epoch 104: validation loss 0.08569693898200989, accuracy 0.7132\n",
      "Epoch 105: validation loss 0.04489178319454193, accuracy 0.70408\n",
      "Epoch 106: validation loss 0.06596372999668121, accuracy 0.71048\n",
      "Epoch 107: validation loss 0.04102642234802246, accuracy 0.67592\n",
      "Epoch 108: validation loss 0.09033422104358674, accuracy 0.65448\n",
      "Epoch 109: validation loss 0.06842533328056336, accuracy 0.70688\n",
      "Epoch 110: validation loss 0.05756611265182495, accuracy 0.70848\n",
      "Epoch 111: validation loss 0.051489442586898804, accuracy 0.68816\n",
      "Epoch 112: validation loss 0.042906870913505556, accuracy 0.68496\n",
      "Epoch 113: validation loss 0.05429186909198761, accuracy 0.71136\n",
      "Epoch 114: validation loss 0.05978043147563934, accuracy 0.71248\n",
      "Epoch 115: validation loss 0.06897796362400055, accuracy 0.67816\n",
      "Epoch 116: validation loss 0.05066678286552429, accuracy 0.69448\n",
      "Epoch 117: validation loss 0.06271373103141785, accuracy 0.69328\n",
      "Epoch 118: validation loss 0.09236446192741395, accuracy 0.64904\n",
      "Epoch 119: validation loss 0.05557332995414734, accuracy 0.66688\n",
      "Epoch 120: validation loss 0.043675898456573485, accuracy 0.69272\n",
      "Epoch 121: validation loss 0.06107153031349182, accuracy 0.69688\n",
      "Epoch 122: validation loss 0.043496646633148194, accuracy 0.67984\n",
      "Epoch 123: validation loss 0.06712768602371216, accuracy 0.6788\n",
      "Epoch 124: validation loss 0.06086260614395141, accuracy 0.64752\n",
      "Epoch 125: validation loss 0.05814469618320465, accuracy 0.69272\n",
      "Epoch 126: validation loss 0.09351932621955872, accuracy 0.70288\n",
      "Epoch 127: validation loss 0.10224946273326874, accuracy 0.70472\n",
      "Epoch 128: validation loss 0.0746176423406601, accuracy 0.70352\n",
      "Epoch 129: validation loss 0.060297399678230286, accuracy 0.69272\n",
      "Epoch 130: validation loss 0.058759237089157104, accuracy 0.654\n",
      "Epoch 131: validation loss 0.07081611793518067, accuracy 0.69264\n",
      "Epoch 132: validation loss 0.04655659056663513, accuracy 0.65824\n",
      "Epoch 133: validation loss 0.06958736284732818, accuracy 0.69792\n",
      "Epoch 134: validation loss 0.0608450076675415, accuracy 0.68864\n",
      "Epoch 135: validation loss 0.07321581469058991, accuracy 0.70288\n",
      "Epoch 136: validation loss 0.11019212914466858, accuracy 0.656\n",
      "Epoch 137: validation loss 0.06339746888160705, accuracy 0.69272\n",
      "Epoch 138: validation loss 0.07233282570838928, accuracy 0.66448\n",
      "Epoch 139: validation loss 0.07400466106891632, accuracy 0.68168\n",
      "Epoch 140: validation loss 0.08253334026813507, accuracy 0.70304\n",
      "Epoch 141: validation loss 0.03342778331756592, accuracy 0.64832\n",
      "Epoch 142: validation loss 0.06752095695495605, accuracy 0.66784\n",
      "Epoch 143: validation loss 0.042908953928947446, accuracy 0.67672\n",
      "Epoch 144: validation loss 0.08140016484737396, accuracy 0.69504\n",
      "Epoch 145: validation loss 0.15940434641838075, accuracy 0.69864\n",
      "Epoch 146: validation loss 0.050542790851593015, accuracy 0.6708\n",
      "Epoch 147: validation loss 0.07145600929260254, accuracy 0.69848\n",
      "Epoch 148: validation loss 0.07486143947601319, accuracy 0.70616\n",
      "Epoch 149: validation loss 0.0771714787864685, accuracy 0.69056\n",
      "Epoch 150: validation loss 0.08698395164489746, accuracy 0.69488\n",
      "Epoch 151: validation loss 0.07401112969875336, accuracy 0.6992\n",
      "Epoch 152: validation loss 0.08439873201847077, accuracy 0.70048\n",
      "Epoch 153: validation loss 0.04657810788154602, accuracy 0.68672\n",
      "Epoch 154: validation loss 0.09839382050514221, accuracy 0.70256\n",
      "Epoch 155: validation loss 0.08740546276569366, accuracy 0.70104\n",
      "Epoch 156: validation loss 0.06009780604362488, accuracy 0.66216\n",
      "Epoch 157: validation loss 0.09129887279987335, accuracy 0.68384\n",
      "Epoch 158: validation loss 0.0998247119808197, accuracy 0.70736\n",
      "Epoch 159: validation loss 0.1444405353450775, accuracy 0.6876\n",
      "Epoch 160: validation loss 0.10077131390094757, accuracy 0.67888\n",
      "Epoch 161: validation loss 0.08205811920166016, accuracy 0.70104\n",
      "Epoch 162: validation loss 0.04612686397075653, accuracy 0.65304\n",
      "Epoch 163: validation loss 0.17079880625724791, accuracy 0.67872\n",
      "Epoch 164: validation loss 0.07970753931045532, accuracy 0.70616\n",
      "Epoch 165: validation loss 0.06387470191955566, accuracy 0.66728\n",
      "Epoch 166: validation loss 0.08062367290496826, accuracy 0.6956\n",
      "Epoch 167: validation loss 0.08151239194869996, accuracy 0.66768\n",
      "Epoch 168: validation loss 0.07771847857475281, accuracy 0.6752\n",
      "Epoch 169: validation loss 0.08930496895790101, accuracy 0.69808\n",
      "Epoch 170: validation loss 0.11999686994075776, accuracy 0.66856\n",
      "Epoch 171: validation loss 0.1032448432636261, accuracy 0.6708\n",
      "Epoch 172: validation loss 0.059924406356811524, accuracy 0.6976\n",
      "Epoch 173: validation loss 0.04902263750076294, accuracy 0.68656\n",
      "Epoch 174: validation loss 0.05135328343391418, accuracy 0.69496\n",
      "Epoch 175: validation loss 0.05045164604663849, accuracy 0.66896\n",
      "Epoch 176: validation loss 0.08411151390552521, accuracy 0.67504\n",
      "Epoch 177: validation loss 0.0639041300201416, accuracy 0.68528\n",
      "Epoch 178: validation loss 0.057659139919281004, accuracy 0.64992\n",
      "Epoch 179: validation loss 0.076109911942482, accuracy 0.67488\n",
      "Epoch 180: validation loss 0.05379527982234955, accuracy 0.66976\n",
      "Epoch 181: validation loss 0.07895131924152374, accuracy 0.70128\n",
      "Epoch 182: validation loss 0.10221981019973755, accuracy 0.70296\n",
      "Epoch 183: validation loss 0.11191142199516296, accuracy 0.6756\n",
      "Epoch 184: validation loss 0.10011946730136871, accuracy 0.69664\n",
      "Epoch 185: validation loss 0.09350889924049377, accuracy 0.68744\n",
      "Epoch 186: validation loss 0.10127931468009949, accuracy 0.69144\n",
      "Epoch 187: validation loss 0.10394574756622314, accuracy 0.6912\n",
      "Epoch 188: validation loss 0.06075907150745392, accuracy 0.69656\n",
      "Epoch 189: validation loss 0.13751111914634703, accuracy 0.64136\n",
      "Epoch 190: validation loss 0.09945374645233154, accuracy 0.68096\n",
      "Epoch 191: validation loss 0.11522646215438843, accuracy 0.6876\n",
      "Epoch 192: validation loss 0.10419085692882538, accuracy 0.6748\n",
      "Epoch 193: validation loss 0.1505580726337433, accuracy 0.68832\n",
      "Epoch 194: validation loss 0.12413151967048645, accuracy 0.68696\n",
      "Epoch 195: validation loss 0.10082203928470612, accuracy 0.6756\n",
      "Epoch 196: validation loss 0.06871156827926636, accuracy 0.65464\n",
      "Epoch 197: validation loss 0.07769719715118409, accuracy 0.69488\n",
      "Epoch 198: validation loss 0.26432448812484743, accuracy 0.6692\n",
      "Epoch 199: validation loss 0.1297477993297577, accuracy 0.67448\n",
      "Epoch 200: validation loss 0.07028765788078307, accuracy 0.67776\n",
      "Epoch 201: validation loss 0.054754198017120365, accuracy 0.682\n",
      "Epoch 202: validation loss 0.1076230523300171, accuracy 0.68112\n",
      "Epoch 203: validation loss 0.08477124680519103, accuracy 0.67704\n",
      "Epoch 204: validation loss 0.0885445135307312, accuracy 0.68112\n",
      "Epoch 205: validation loss 0.1376993058490753, accuracy 0.6864\n",
      "Epoch 206: validation loss 0.11715797911643983, accuracy 0.68672\n",
      "Epoch 207: validation loss 0.09280151274681091, accuracy 0.67864\n",
      "Epoch 208: validation loss 0.12746871556282044, accuracy 0.65616\n",
      "Epoch 209: validation loss 0.11106046007156373, accuracy 0.68608\n",
      "Epoch 210: validation loss 0.058306220121383666, accuracy 0.65648\n",
      "Epoch 211: validation loss 0.12202193500041962, accuracy 0.70048\n",
      "Epoch 212: validation loss 0.08535401332855225, accuracy 0.66712\n",
      "Epoch 213: validation loss 0.11350788258075714, accuracy 0.68208\n",
      "Epoch 214: validation loss 0.16848196122169495, accuracy 0.70016\n",
      "Epoch 215: validation loss 0.20467300820350648, accuracy 0.69368\n",
      "Epoch 216: validation loss 0.044925337953567505, accuracy 0.6504\n",
      "Epoch 217: validation loss 0.07346790100097657, accuracy 0.64072\n",
      "Epoch 218: validation loss 0.284050747051239, accuracy 0.67992\n",
      "Epoch 219: validation loss 0.10478330309867859, accuracy 0.65264\n",
      "Epoch 220: validation loss 0.08152897349357605, accuracy 0.67856\n",
      "Epoch 221: validation loss 0.08585974969863891, accuracy 0.69344\n",
      "Epoch 222: validation loss 0.07409086540222168, accuracy 0.65648\n",
      "Epoch 223: validation loss 0.14986747687339783, accuracy 0.65728\n",
      "Epoch 224: validation loss 0.10520197937011719, accuracy 0.69408\n",
      "Epoch 225: validation loss 0.08372206055641174, accuracy 0.65424\n",
      "Epoch 226: validation loss 0.07839793862819672, accuracy 0.66824\n",
      "Epoch 227: validation loss 0.13753058286190034, accuracy 0.69624\n",
      "Epoch 228: validation loss 0.07298111147880554, accuracy 0.69056\n",
      "Epoch 229: validation loss 0.18438427925109863, accuracy 0.70336\n",
      "Epoch 230: validation loss 0.1189291113948822, accuracy 0.70392\n",
      "Epoch 231: validation loss 0.09439332712173462, accuracy 0.67808\n",
      "Epoch 232: validation loss 0.15511514305114746, accuracy 0.68168\n",
      "Epoch 233: validation loss 0.08158629004478454, accuracy 0.6384\n",
      "Epoch 234: validation loss 0.09768784674167633, accuracy 0.66376\n",
      "Epoch 235: validation loss 0.21687143043518067, accuracy 0.69088\n",
      "Epoch 236: validation loss 0.16998706917762757, accuracy 0.6748\n",
      "Epoch 237: validation loss 0.06234087851524353, accuracy 0.6344\n",
      "Epoch 238: validation loss 0.12049340740203858, accuracy 0.69016\n",
      "Epoch 239: validation loss 0.17815405115127564, accuracy 0.65376\n",
      "Epoch 240: validation loss 0.1299484081554413, accuracy 0.69352\n",
      "Epoch 241: validation loss 0.1120616750049591, accuracy 0.6896\n",
      "Epoch 242: validation loss 0.10181389174461365, accuracy 0.6536\n",
      "Epoch 243: validation loss 0.2734704457950592, accuracy 0.69\n",
      "Epoch 244: validation loss 0.14284199031829833, accuracy 0.67112\n",
      "Epoch 245: validation loss 0.1384532041978836, accuracy 0.69768\n",
      "Epoch 246: validation loss 0.13723300209999084, accuracy 0.68368\n",
      "Epoch 247: validation loss 0.14875567286491395, accuracy 0.67848\n",
      "Epoch 248: validation loss 0.13510043870925903, accuracy 0.67256\n",
      "Epoch 249: validation loss 0.1547435759162903, accuracy 0.70288\n",
      "Epoch 250: validation loss 0.09511371500015259, accuracy 0.63648\n",
      "Epoch 251: validation loss 0.12624284498214722, accuracy 0.69744\n",
      "Epoch 252: validation loss 0.22774123197555543, accuracy 0.6696\n",
      "Epoch 253: validation loss 0.17354801847457885, accuracy 0.70056\n",
      "Epoch 254: validation loss 0.07895624219417573, accuracy 0.67688\n",
      "Epoch 255: validation loss 0.10458755586147309, accuracy 0.67648\n",
      "Epoch 256: validation loss 0.08501653392791748, accuracy 0.682\n",
      "Epoch 257: validation loss 0.08930254559516906, accuracy 0.6624\n",
      "Epoch 258: validation loss 0.166570481672287, accuracy 0.59616\n",
      "Epoch 259: validation loss 0.06628335354328156, accuracy 0.65496\n",
      "Epoch 260: validation loss 0.20020449785232544, accuracy 0.70384\n",
      "Epoch 261: validation loss 0.12400809500217437, accuracy 0.6964\n",
      "Epoch 262: validation loss 0.17904013639450073, accuracy 0.61352\n",
      "Epoch 263: validation loss 0.11197360107421875, accuracy 0.66328\n",
      "Epoch 264: validation loss 0.10793755643844605, accuracy 0.63552\n",
      "Epoch 265: validation loss 0.16386098014831543, accuracy 0.68848\n",
      "Epoch 266: validation loss 0.13146687139987945, accuracy 0.68184\n",
      "Epoch 267: validation loss 0.09080732690811157, accuracy 0.6696\n",
      "Epoch 268: validation loss 0.11461584886550903, accuracy 0.69304\n",
      "Epoch 269: validation loss 0.0917732706975937, accuracy 0.67384\n",
      "Epoch 270: validation loss 0.10591670347690582, accuracy 0.68352\n",
      "Epoch 271: validation loss 0.11319917963981628, accuracy 0.67824\n",
      "Epoch 272: validation loss 0.13809488827228547, accuracy 0.67104\n",
      "Epoch 273: validation loss 0.1626716898727417, accuracy 0.67344\n",
      "Epoch 274: validation loss 0.15627316267967223, accuracy 0.6544\n",
      "Epoch 275: validation loss 0.10130237378120423, accuracy 0.6852\n",
      "Epoch 276: validation loss 0.28422332767486574, accuracy 0.65776\n",
      "Epoch 277: validation loss 0.16192638219833375, accuracy 0.6764\n",
      "Epoch 278: validation loss 0.2021595276927948, accuracy 0.69968\n",
      "Epoch 279: validation loss 0.1215314248418808, accuracy 0.6484\n",
      "Epoch 280: validation loss 0.3667404334449768, accuracy 0.67744\n",
      "Epoch 281: validation loss 0.17763861404418946, accuracy 0.68776\n",
      "Epoch 282: validation loss 0.12404316318511963, accuracy 0.68656\n",
      "Epoch 283: validation loss 0.15749015964031218, accuracy 0.67128\n",
      "Epoch 284: validation loss 0.07733433549404144, accuracy 0.66008\n",
      "Epoch 285: validation loss 0.1995182582950592, accuracy 0.68\n",
      "Epoch 286: validation loss 0.13397829835891722, accuracy 0.65432\n",
      "Epoch 287: validation loss 0.058095749950408934, accuracy 0.63368\n",
      "Epoch 288: validation loss 0.10719036028862, accuracy 0.65184\n",
      "Epoch 289: validation loss 0.08332669738769531, accuracy 0.6632\n",
      "Epoch 290: validation loss 0.10353251911640167, accuracy 0.67552\n",
      "Epoch 291: validation loss 0.08173467406272888, accuracy 0.63696\n",
      "Epoch 292: validation loss 0.09785362928390504, accuracy 0.68664\n",
      "Epoch 293: validation loss 0.23415050468444823, accuracy 0.65232\n",
      "Epoch 294: validation loss 0.10756222193717957, accuracy 0.67072\n",
      "Epoch 295: validation loss 0.1462665410423279, accuracy 0.66704\n",
      "Epoch 296: validation loss 0.1910635040330887, accuracy 0.69608\n",
      "Epoch 297: validation loss 0.0977441907119751, accuracy 0.69136\n",
      "Epoch 298: validation loss 0.10508600603103638, accuracy 0.66592\n",
      "Epoch 299: validation loss 0.3196883315563202, accuracy 0.64824\n",
      "Epoch 300: validation loss 0.08496116956710816, accuracy 0.66184\n",
      "Epoch 301: validation loss 0.19946152739524842, accuracy 0.68352\n",
      "Epoch 302: validation loss 0.22660344467163085, accuracy 0.69256\n",
      "Epoch 303: validation loss 0.14258775394916534, accuracy 0.65992\n",
      "Epoch 304: validation loss 0.12527634684562683, accuracy 0.66968\n",
      "Epoch 305: validation loss 0.15418874048233033, accuracy 0.68432\n",
      "Epoch 306: validation loss 0.6467681902313233, accuracy 0.66896\n",
      "Epoch 307: validation loss 0.13666173217773436, accuracy 0.65232\n",
      "Epoch 308: validation loss 0.1365641405105591, accuracy 0.646\n",
      "Epoch 309: validation loss 0.1930979576778412, accuracy 0.698\n",
      "Epoch 310: validation loss 0.10220332011699676, accuracy 0.59624\n",
      "Epoch 311: validation loss 0.13488680259227753, accuracy 0.67952\n",
      "Epoch 312: validation loss 0.17027994414329528, accuracy 0.66384\n",
      "Epoch 313: validation loss 0.22115739524841307, accuracy 0.68552\n",
      "Epoch 314: validation loss 0.27305956656455993, accuracy 0.66976\n",
      "Epoch 315: validation loss 0.23011846987724305, accuracy 0.6832\n",
      "Epoch 316: validation loss 0.4049075770187378, accuracy 0.67544\n",
      "Epoch 317: validation loss 0.13254303806304932, accuracy 0.68136\n",
      "Epoch 318: validation loss 0.14437684891223906, accuracy 0.67496\n",
      "Epoch 319: validation loss 0.200493950881958, accuracy 0.69696\n",
      "Epoch 320: validation loss 0.22826337320327758, accuracy 0.63128\n",
      "Epoch 321: validation loss 0.1681053365802765, accuracy 0.67592\n",
      "Epoch 322: validation loss 0.14003508761882782, accuracy 0.67208\n",
      "Epoch 323: validation loss 0.14217241156101226, accuracy 0.67528\n",
      "Epoch 324: validation loss 0.1829208547782898, accuracy 0.69312\n",
      "Epoch 325: validation loss 0.18987110020637513, accuracy 0.63744\n",
      "Epoch 326: validation loss 0.17104289319515228, accuracy 0.65528\n",
      "Epoch 327: validation loss 0.28522689836502074, accuracy 0.70544\n",
      "Epoch 328: validation loss 0.21789700318336486, accuracy 0.69304\n",
      "Epoch 329: validation loss 0.2097495572566986, accuracy 0.6812\n",
      "Epoch 330: validation loss 0.2023666854953766, accuracy 0.67368\n",
      "Epoch 331: validation loss 0.17200401182174682, accuracy 0.68496\n",
      "Epoch 332: validation loss 0.14203200376987457, accuracy 0.67336\n",
      "Epoch 333: validation loss 0.1032390342092514, accuracy 0.67496\n",
      "Epoch 334: validation loss 0.20464393671035766, accuracy 0.66664\n",
      "Epoch 335: validation loss 0.2466914222431183, accuracy 0.6656\n",
      "Epoch 336: validation loss 0.1993628911972046, accuracy 0.67544\n",
      "Epoch 337: validation loss 0.13843434464454651, accuracy 0.68272\n",
      "Epoch 338: validation loss 0.1431495176410675, accuracy 0.66776\n",
      "Epoch 339: validation loss 0.1030700101852417, accuracy 0.65648\n",
      "Epoch 340: validation loss 0.23936199501037597, accuracy 0.67232\n",
      "Epoch 341: validation loss 0.23269868362426757, accuracy 0.66576\n",
      "Epoch 342: validation loss 0.3222923857116699, accuracy 0.69768\n",
      "Epoch 343: validation loss 0.16436142382621766, accuracy 0.64608\n",
      "Epoch 344: validation loss 0.11557536537647248, accuracy 0.65264\n",
      "Epoch 345: validation loss 0.19214935983657838, accuracy 0.66944\n",
      "Epoch 346: validation loss 0.18345415949821473, accuracy 0.67888\n",
      "Epoch 347: validation loss 0.18529141772270202, accuracy 0.67752\n",
      "Epoch 348: validation loss 0.12862649103164672, accuracy 0.6308\n",
      "Epoch 349: validation loss 0.18865885160446166, accuracy 0.69792\n",
      "Epoch 350: validation loss 0.13491350355625154, accuracy 0.66968\n",
      "Epoch 351: validation loss 0.11959310763835906, accuracy 0.65088\n",
      "Epoch 352: validation loss 0.17824771463394165, accuracy 0.66088\n",
      "Epoch 353: validation loss 0.14679657869338988, accuracy 0.65232\n",
      "Epoch 354: validation loss 0.17023410000801087, accuracy 0.68368\n",
      "Epoch 355: validation loss 0.25913363224983216, accuracy 0.68104\n",
      "Epoch 356: validation loss 0.24791044592857361, accuracy 0.68208\n",
      "Epoch 357: validation loss 0.16141023713588715, accuracy 0.66664\n",
      "Epoch 358: validation loss 0.16053201939105988, accuracy 0.62256\n",
      "Epoch 359: validation loss 0.12481494678020477, accuracy 0.668\n",
      "Epoch 360: validation loss 0.1789611691713333, accuracy 0.67288\n",
      "Epoch 361: validation loss 0.13155537048816682, accuracy 0.66184\n",
      "Epoch 362: validation loss 0.09666760330200196, accuracy 0.66704\n",
      "Epoch 363: validation loss 0.13058170710086822, accuracy 0.6484\n",
      "Epoch 364: validation loss 0.2288326683807373, accuracy 0.6768\n",
      "Epoch 365: validation loss 0.1806467136859894, accuracy 0.67224\n",
      "Epoch 366: validation loss 0.3962194997596741, accuracy 0.6736\n",
      "Epoch 367: validation loss 0.17175121894836426, accuracy 0.67312\n",
      "Epoch 368: validation loss 0.13965336696147918, accuracy 0.6684\n",
      "Epoch 369: validation loss 0.13299280682563783, accuracy 0.64424\n",
      "Epoch 370: validation loss 0.24046706169128418, accuracy 0.69736\n",
      "Epoch 371: validation loss 0.2498699404335022, accuracy 0.676\n",
      "Epoch 372: validation loss 0.10165619519233704, accuracy 0.60408\n",
      "Epoch 373: validation loss 0.20037339442253113, accuracy 0.65672\n",
      "Epoch 374: validation loss 0.1915974856567383, accuracy 0.66552\n",
      "Epoch 375: validation loss 0.15107301851272584, accuracy 0.62944\n",
      "Epoch 376: validation loss 0.18645772210121156, accuracy 0.67208\n",
      "Epoch 377: validation loss 0.2127314170074463, accuracy 0.67\n",
      "Epoch 378: validation loss 0.17538852781295777, accuracy 0.66064\n",
      "Epoch 379: validation loss 0.2309551786518097, accuracy 0.6968\n",
      "Epoch 380: validation loss 0.3076881057548523, accuracy 0.66488\n",
      "Epoch 381: validation loss 0.3531090238571167, accuracy 0.69696\n",
      "Epoch 382: validation loss 0.28352414129257203, accuracy 0.6976\n",
      "Epoch 383: validation loss 0.29861045958518984, accuracy 0.67792\n",
      "Epoch 384: validation loss 0.18974263154029847, accuracy 0.67488\n",
      "Epoch 385: validation loss 0.22811476163864136, accuracy 0.6628\n",
      "Epoch 386: validation loss 0.2956165187931061, accuracy 0.68704\n",
      "Epoch 387: validation loss 0.2845127645587921, accuracy 0.66536\n",
      "Epoch 388: validation loss 0.2780716544151306, accuracy 0.64256\n",
      "Epoch 389: validation loss 0.1427961165189743, accuracy 0.65048\n",
      "Epoch 390: validation loss 0.1975095644569397, accuracy 0.64896\n",
      "Epoch 391: validation loss 0.28234013916015627, accuracy 0.63144\n",
      "Epoch 392: validation loss 0.14754078230857848, accuracy 0.66336\n",
      "Epoch 393: validation loss 0.18406560625076293, accuracy 0.6684\n",
      "Epoch 394: validation loss 0.2616629473638535, accuracy 0.6672\n",
      "Epoch 395: validation loss 0.46934885944366456, accuracy 0.64424\n",
      "Epoch 396: validation loss 0.1383330304813385, accuracy 0.63616\n",
      "Epoch 397: validation loss 0.14321418232917785, accuracy 0.64216\n",
      "Epoch 398: validation loss 0.19266666935920715, accuracy 0.66216\n",
      "Epoch 399: validation loss 0.36375991500854493, accuracy 0.61848\n",
      "Epoch 400: validation loss 0.2782145524024963, accuracy 0.66472\n",
      "Final test set performance:\n",
      "\tloss 0.28585022292137147\n",
      "\taccuracy 0.6613\n"
     ]
    }
   ],
   "source": [
    "run_centralized(experiments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: validation loss 0.06441693063735962, accuracy 0.06976\n",
      "Epoch 2: validation loss 0.05947630434036255, accuracy 0.12296\n",
      "Epoch 3: validation loss 0.05646490665435791, accuracy 0.1512\n",
      "Epoch 4: validation loss 0.053201660423278806, accuracy 0.19216\n",
      "Epoch 5: validation loss 0.05117382019042969, accuracy 0.21968\n",
      "Epoch 6: validation loss 0.050081351013183596, accuracy 0.24328\n",
      "Epoch 7: validation loss 0.049269660911560056, accuracy 0.25688\n",
      "Epoch 8: validation loss 0.05062286931991577, accuracy 0.25696\n",
      "Epoch 9: validation loss 0.05255579975128174, accuracy 0.25688\n",
      "Epoch 10: validation loss 0.05546677583694458, accuracy 0.25712\n",
      "Epoch 11: validation loss 0.061887386436462404, accuracy 0.2492\n",
      "Epoch 12: validation loss 0.06774099569320678, accuracy 0.24688\n",
      "Epoch 13: validation loss 0.07612566272735596, accuracy 0.24784\n",
      "Epoch 14: validation loss 0.08541844493865967, accuracy 0.24088\n",
      "Epoch 15: validation loss 0.09222926691055298, accuracy 0.234\n",
      "Epoch 16: validation loss 0.09543277019500733, accuracy 0.23336\n",
      "Epoch 17: validation loss 0.1078676071548462, accuracy 0.23736\n",
      "Epoch 18: validation loss 0.11630103263854981, accuracy 0.22136\n",
      "Epoch 19: validation loss 0.11545056907653808, accuracy 0.23464\n",
      "Epoch 20: validation loss 0.12233723861694336, accuracy 0.22632\n",
      "Epoch 21: validation loss 0.1303577282333374, accuracy 0.23072\n",
      "Epoch 22: validation loss 0.144873274269104, accuracy 0.22152\n",
      "Epoch 23: validation loss 0.14471026912689208, accuracy 0.22832\n",
      "Epoch 24: validation loss 0.15169422504425048, accuracy 0.23176\n",
      "Epoch 25: validation loss 0.14902031986236572, accuracy 0.2264\n",
      "Epoch 26: validation loss 0.1558727014160156, accuracy 0.23128\n",
      "Epoch 27: validation loss 0.15233268348693849, accuracy 0.23184\n",
      "Epoch 28: validation loss 0.16331072330474852, accuracy 0.23232\n",
      "Epoch 29: validation loss 0.16911904525756835, accuracy 0.23064\n",
      "Epoch 30: validation loss 0.16435686378479003, accuracy 0.23192\n",
      "Epoch 31: validation loss 0.17366594654083253, accuracy 0.22248\n",
      "Epoch 32: validation loss 0.17595367877960205, accuracy 0.22968\n",
      "Epoch 33: validation loss 0.18470610980987548, accuracy 0.22904\n",
      "Epoch 34: validation loss 0.19530095909118653, accuracy 0.2252\n",
      "Epoch 35: validation loss 0.20689812599182128, accuracy 0.22872\n",
      "Epoch 36: validation loss 0.2033270245361328, accuracy 0.22112\n",
      "Epoch 37: validation loss 0.19299815380096436, accuracy 0.23\n",
      "Epoch 38: validation loss 0.205553740234375, accuracy 0.22336\n",
      "Epoch 39: validation loss 0.20921729293823244, accuracy 0.22608\n",
      "Epoch 40: validation loss 0.19778678115844728, accuracy 0.22288\n",
      "Epoch 41: validation loss 0.20727265754699706, accuracy 0.22312\n",
      "Epoch 42: validation loss 0.2118792677307129, accuracy 0.23096\n",
      "Epoch 43: validation loss 0.21398569107055665, accuracy 0.22728\n",
      "Epoch 44: validation loss 0.2264599993133545, accuracy 0.22744\n",
      "Epoch 45: validation loss 0.21582668338775635, accuracy 0.22912\n",
      "Epoch 46: validation loss 0.23695642333984376, accuracy 0.226\n",
      "Epoch 47: validation loss 0.22709127769470214, accuracy 0.22688\n",
      "Epoch 48: validation loss 0.25078881896972655, accuracy 0.234\n",
      "Epoch 49: validation loss 0.23366696228027345, accuracy 0.22712\n",
      "Epoch 50: validation loss 0.24381799682617186, accuracy 0.2308\n",
      "Epoch 51: validation loss 0.2377606960296631, accuracy 0.22696\n",
      "Epoch 52: validation loss 0.2480093167114258, accuracy 0.21912\n",
      "Epoch 53: validation loss 0.2418841709136963, accuracy 0.21936\n",
      "Epoch 54: validation loss 0.25041416557312013, accuracy 0.2192\n",
      "Epoch 55: validation loss 0.261421763381958, accuracy 0.22464\n",
      "Epoch 56: validation loss 0.2481086325073242, accuracy 0.21616\n",
      "Epoch 57: validation loss 0.25545971633911135, accuracy 0.22112\n",
      "Epoch 58: validation loss 0.26145236450195314, accuracy 0.22752\n",
      "Epoch 59: validation loss 0.2627473818206787, accuracy 0.22008\n",
      "Epoch 60: validation loss 0.28623908782958984, accuracy 0.22552\n",
      "Epoch 61: validation loss 0.26994426567077634, accuracy 0.2244\n",
      "Epoch 62: validation loss 0.27739860107421876, accuracy 0.22776\n",
      "Epoch 63: validation loss 0.270109542388916, accuracy 0.22296\n",
      "Epoch 64: validation loss 0.2900047756958008, accuracy 0.228\n",
      "Epoch 65: validation loss 0.30056983222961425, accuracy 0.22536\n",
      "Epoch 66: validation loss 0.2942879634857178, accuracy 0.22008\n",
      "Epoch 67: validation loss 0.3099194469451904, accuracy 0.22064\n",
      "Epoch 68: validation loss 0.3207023585510254, accuracy 0.22688\n",
      "Epoch 69: validation loss 0.3197383304595947, accuracy 0.2224\n",
      "Epoch 70: validation loss 0.2984968778991699, accuracy 0.22008\n",
      "Epoch 71: validation loss 0.3041364616394043, accuracy 0.21856\n",
      "Epoch 72: validation loss 0.3289357466125488, accuracy 0.21536\n",
      "Epoch 73: validation loss 0.33453653518676757, accuracy 0.22112\n",
      "Epoch 74: validation loss 0.3268933740234375, accuracy 0.22584\n",
      "Epoch 75: validation loss 0.339319076385498, accuracy 0.21832\n",
      "Epoch 76: validation loss 0.3239896342468262, accuracy 0.2164\n",
      "Epoch 77: validation loss 0.34361126892089844, accuracy 0.2268\n",
      "Epoch 78: validation loss 0.36045849151611326, accuracy 0.21928\n",
      "Epoch 79: validation loss 0.3649828586578369, accuracy 0.22904\n",
      "Epoch 80: validation loss 0.3490230591583252, accuracy 0.21968\n",
      "Epoch 81: validation loss 0.3955687060546875, accuracy 0.22328\n",
      "Epoch 82: validation loss 0.3835144602203369, accuracy 0.2244\n",
      "Epoch 83: validation loss 0.39094941543579104, accuracy 0.22552\n",
      "Epoch 84: validation loss 0.37910328201293947, accuracy 0.22096\n",
      "Epoch 85: validation loss 0.3840675467681885, accuracy 0.22632\n",
      "Epoch 86: validation loss 0.36487838638305664, accuracy 0.22368\n",
      "Epoch 87: validation loss 0.3650218288421631, accuracy 0.222\n",
      "Epoch 88: validation loss 0.3936336701965332, accuracy 0.23384\n",
      "Epoch 89: validation loss 0.38225498573303224, accuracy 0.22768\n",
      "Epoch 90: validation loss 0.4123639263916016, accuracy 0.22048\n",
      "Epoch 91: validation loss 0.4018090396118164, accuracy 0.22256\n",
      "Epoch 92: validation loss 0.415353212890625, accuracy 0.22296\n",
      "Epoch 93: validation loss 0.43619103424072264, accuracy 0.22344\n",
      "Epoch 94: validation loss 0.43735684707641603, accuracy 0.22408\n",
      "Epoch 95: validation loss 0.40821947624206545, accuracy 0.2192\n",
      "Epoch 96: validation loss 0.43924707336425783, accuracy 0.22776\n",
      "Epoch 97: validation loss 0.46245905181884767, accuracy 0.22528\n",
      "Epoch 98: validation loss 0.4359958055114746, accuracy 0.21992\n",
      "Epoch 99: validation loss 0.4381933784484863, accuracy 0.22328\n",
      "Epoch 100: validation loss 0.4753487181091309, accuracy 0.22216\n",
      "Epoch 101: validation loss 0.4443158483886719, accuracy 0.21872\n",
      "Epoch 102: validation loss 0.4428688403320313, accuracy 0.21624\n",
      "Epoch 103: validation loss 0.5110205551147461, accuracy 0.23216\n",
      "Epoch 104: validation loss 0.48589349853515623, accuracy 0.22336\n",
      "Epoch 105: validation loss 0.4674814613342285, accuracy 0.22288\n",
      "Epoch 106: validation loss 0.467403065032959, accuracy 0.22208\n",
      "Epoch 107: validation loss 0.4824955627441406, accuracy 0.2196\n",
      "Epoch 108: validation loss 0.5123217167663574, accuracy 0.22432\n",
      "Epoch 109: validation loss 0.5055105746459961, accuracy 0.22344\n",
      "Epoch 110: validation loss 0.4773007945251465, accuracy 0.22216\n",
      "Epoch 111: validation loss 0.5051357431030273, accuracy 0.22656\n",
      "Epoch 112: validation loss 0.533346764831543, accuracy 0.226\n",
      "Epoch 113: validation loss 0.5371021224975586, accuracy 0.22992\n",
      "Epoch 114: validation loss 0.5356764260864257, accuracy 0.22928\n",
      "Epoch 115: validation loss 0.5258345227050781, accuracy 0.22136\n",
      "Epoch 116: validation loss 0.5607305137634278, accuracy 0.2228\n",
      "Epoch 117: validation loss 0.5771314543151855, accuracy 0.22848\n",
      "Epoch 118: validation loss 0.5953812339782715, accuracy 0.22784\n",
      "Epoch 119: validation loss 0.6386016716003418, accuracy 0.23016\n",
      "Epoch 120: validation loss 0.5836028504943848, accuracy 0.226\n",
      "Epoch 121: validation loss 0.5924608824157714, accuracy 0.2296\n",
      "Epoch 122: validation loss 0.5738934254455567, accuracy 0.22256\n",
      "Epoch 123: validation loss 0.5484103327941895, accuracy 0.21632\n",
      "Epoch 124: validation loss 0.6406895712280274, accuracy 0.22\n",
      "Epoch 125: validation loss 0.5920683380126953, accuracy 0.22712\n",
      "Epoch 126: validation loss 0.599576484222412, accuracy 0.23072\n",
      "Epoch 127: validation loss 0.6301154864501953, accuracy 0.22224\n",
      "Epoch 128: validation loss 0.6473874481201172, accuracy 0.21672\n",
      "Epoch 129: validation loss 0.6691752932739258, accuracy 0.22176\n",
      "Epoch 130: validation loss 0.6198539460754394, accuracy 0.22344\n",
      "Epoch 131: validation loss 0.6310700738525391, accuracy 0.22904\n",
      "Epoch 132: validation loss 0.6927215151977539, accuracy 0.22944\n",
      "Epoch 133: validation loss 0.6226729585266113, accuracy 0.22576\n",
      "Epoch 134: validation loss 0.647495408782959, accuracy 0.22696\n",
      "Epoch 135: validation loss 0.6426927742004395, accuracy 0.21784\n",
      "Epoch 136: validation loss 0.6981556234741211, accuracy 0.22928\n",
      "Epoch 137: validation loss 0.672719518737793, accuracy 0.21968\n",
      "Epoch 138: validation loss 0.6826997618103028, accuracy 0.22224\n",
      "Epoch 139: validation loss 0.7186779391479492, accuracy 0.2268\n",
      "Epoch 140: validation loss 0.7221204144287109, accuracy 0.22904\n",
      "Epoch 141: validation loss 0.7906566209411621, accuracy 0.22384\n",
      "Epoch 142: validation loss 0.7365788670349122, accuracy 0.22016\n",
      "Epoch 143: validation loss 0.7443578416442871, accuracy 0.22656\n",
      "Epoch 144: validation loss 0.7130024594116211, accuracy 0.222\n",
      "Epoch 145: validation loss 0.7616061529541016, accuracy 0.22992\n",
      "Epoch 146: validation loss 0.7521139225769043, accuracy 0.22112\n",
      "Epoch 147: validation loss 0.7548612272644043, accuracy 0.22488\n",
      "Epoch 148: validation loss 0.780702426147461, accuracy 0.22776\n",
      "Epoch 149: validation loss 0.7362987728881836, accuracy 0.22792\n",
      "Epoch 150: validation loss 0.8146953091430664, accuracy 0.22608\n",
      "Epoch 151: validation loss 0.7589342991638184, accuracy 0.2216\n",
      "Epoch 152: validation loss 0.7492772399902343, accuracy 0.22064\n",
      "Epoch 153: validation loss 0.8187836737060546, accuracy 0.22152\n",
      "Epoch 154: validation loss 0.818327017364502, accuracy 0.2228\n",
      "Epoch 155: validation loss 0.7800801480102539, accuracy 0.2264\n",
      "Epoch 156: validation loss 0.8334942001342773, accuracy 0.21992\n",
      "Epoch 157: validation loss 0.8363849911499024, accuracy 0.2284\n",
      "Epoch 158: validation loss 0.884064631652832, accuracy 0.22144\n",
      "Epoch 159: validation loss 0.8831176263427735, accuracy 0.22248\n",
      "Epoch 160: validation loss 0.8805773376464844, accuracy 0.21968\n",
      "Epoch 161: validation loss 0.8931037982177734, accuracy 0.2172\n",
      "Epoch 162: validation loss 0.9003322085571289, accuracy 0.22512\n",
      "Epoch 163: validation loss 0.8694849325561523, accuracy 0.22272\n",
      "Epoch 164: validation loss 0.8892941921997071, accuracy 0.22384\n",
      "Epoch 165: validation loss 0.8584914395141602, accuracy 0.22408\n",
      "Epoch 166: validation loss 0.8530391009521484, accuracy 0.21704\n",
      "Epoch 167: validation loss 0.94247431640625, accuracy 0.2264\n",
      "Epoch 168: validation loss 0.9189117926025391, accuracy 0.21944\n",
      "Epoch 169: validation loss 0.9456909716796875, accuracy 0.23128\n",
      "Epoch 170: validation loss 0.9473048056030273, accuracy 0.23168\n",
      "Epoch 171: validation loss 0.9448008053588867, accuracy 0.22112\n",
      "Epoch 172: validation loss 0.9958463653564453, accuracy 0.22136\n",
      "Epoch 173: validation loss 1.0155460232543945, accuracy 0.22184\n",
      "Epoch 174: validation loss 0.9820872723388672, accuracy 0.21912\n",
      "Epoch 175: validation loss 0.9399347204589844, accuracy 0.22\n",
      "Epoch 176: validation loss 0.9720743518066406, accuracy 0.22512\n",
      "Epoch 177: validation loss 0.9591788360595703, accuracy 0.22896\n",
      "Epoch 178: validation loss 1.0168885308837892, accuracy 0.22352\n",
      "Epoch 179: validation loss 1.0003810122680663, accuracy 0.21864\n",
      "Epoch 180: validation loss 0.9798347570800782, accuracy 0.22328\n",
      "Epoch 181: validation loss 1.0512129119873046, accuracy 0.23008\n",
      "Epoch 182: validation loss 1.096350651550293, accuracy 0.22624\n",
      "Epoch 183: validation loss 1.0774840090942384, accuracy 0.22712\n",
      "Epoch 184: validation loss 1.0055831411743164, accuracy 0.2252\n",
      "Epoch 185: validation loss 1.0454513674926758, accuracy 0.2216\n",
      "Epoch 186: validation loss 1.0609653637695313, accuracy 0.22128\n",
      "Epoch 187: validation loss 1.1207876556396483, accuracy 0.23048\n",
      "Epoch 188: validation loss 1.1060943493652344, accuracy 0.22392\n",
      "Epoch 189: validation loss 1.1764119412231446, accuracy 0.22464\n",
      "Epoch 190: validation loss 1.1597640216064453, accuracy 0.22\n",
      "Epoch 191: validation loss 1.1715069595336913, accuracy 0.22392\n",
      "Epoch 192: validation loss 1.1189400701904297, accuracy 0.22376\n",
      "Epoch 193: validation loss 1.177184475402832, accuracy 0.2288\n",
      "Epoch 194: validation loss 1.1956318780517579, accuracy 0.21936\n",
      "Epoch 195: validation loss 1.1907950906372071, accuracy 0.22528\n",
      "Epoch 196: validation loss 1.1867000469970703, accuracy 0.22888\n",
      "Epoch 197: validation loss 1.1783955465698241, accuracy 0.22352\n",
      "Epoch 198: validation loss 1.2317948120117188, accuracy 0.22368\n",
      "Epoch 199: validation loss 1.3114285055541992, accuracy 0.21584\n",
      "Epoch 200: validation loss 1.217700933227539, accuracy 0.2288\n",
      "Epoch 201: validation loss 1.2199428283691407, accuracy 0.22544\n",
      "Epoch 202: validation loss 1.2626631051635742, accuracy 0.22944\n",
      "Epoch 203: validation loss 1.2122965612792969, accuracy 0.22296\n",
      "Epoch 204: validation loss 1.2753772341918945, accuracy 0.22104\n",
      "Epoch 205: validation loss 1.2017774636840821, accuracy 0.21992\n",
      "Epoch 206: validation loss 1.2936623214721679, accuracy 0.22728\n",
      "Epoch 207: validation loss 1.2288525372314454, accuracy 0.2272\n",
      "Epoch 208: validation loss 1.3506109979248047, accuracy 0.22352\n",
      "Epoch 209: validation loss 1.241524553527832, accuracy 0.22232\n",
      "Epoch 210: validation loss 1.2895406240844727, accuracy 0.22464\n",
      "Epoch 211: validation loss 1.460061999206543, accuracy 0.22784\n",
      "Epoch 212: validation loss 1.3798992150878906, accuracy 0.22712\n",
      "Epoch 213: validation loss 1.372064621887207, accuracy 0.21936\n",
      "Epoch 214: validation loss 1.3784108279418945, accuracy 0.2204\n",
      "Epoch 215: validation loss 1.4599886605834962, accuracy 0.22856\n",
      "Epoch 216: validation loss 1.4400547384643554, accuracy 0.224\n",
      "Epoch 217: validation loss 1.4437915921020508, accuracy 0.22688\n",
      "Epoch 218: validation loss 1.4308760531616211, accuracy 0.22368\n",
      "Epoch 219: validation loss 1.4640115017700195, accuracy 0.22424\n",
      "Epoch 220: validation loss 1.412346495666504, accuracy 0.22256\n",
      "Epoch 221: validation loss 1.5168687619018555, accuracy 0.22176\n",
      "Epoch 222: validation loss 1.4697856231689452, accuracy 0.21728\n",
      "Epoch 223: validation loss 1.4255300268554687, accuracy 0.22384\n",
      "Epoch 224: validation loss 1.5070119421386718, accuracy 0.22336\n",
      "Epoch 225: validation loss 1.4927588903808593, accuracy 0.22808\n",
      "Epoch 226: validation loss 1.5160022052001954, accuracy 0.22704\n",
      "Epoch 227: validation loss 1.4237460342407227, accuracy 0.22448\n",
      "Epoch 228: validation loss 1.6032607125854492, accuracy 0.22712\n",
      "Epoch 229: validation loss 1.5384882424926758, accuracy 0.228\n",
      "Epoch 230: validation loss 1.5232103271484374, accuracy 0.22568\n",
      "Epoch 231: validation loss 1.535629054260254, accuracy 0.22096\n",
      "Epoch 232: validation loss 1.5148269439697266, accuracy 0.22152\n",
      "Epoch 233: validation loss 1.6252409121704101, accuracy 0.22416\n",
      "Epoch 234: validation loss 1.6934221295166016, accuracy 0.22784\n",
      "Epoch 235: validation loss 1.7208110900878906, accuracy 0.22664\n",
      "Epoch 236: validation loss 1.761458966064453, accuracy 0.22264\n",
      "Epoch 237: validation loss 1.61820087890625, accuracy 0.22448\n",
      "Epoch 238: validation loss 1.6955125497436523, accuracy 0.22328\n",
      "Epoch 239: validation loss 1.7291717657470702, accuracy 0.22544\n",
      "Epoch 240: validation loss 1.6132965606689453, accuracy 0.21944\n",
      "Epoch 241: validation loss 1.7015974011230468, accuracy 0.22544\n",
      "Epoch 242: validation loss 1.67433608001709, accuracy 0.22328\n",
      "Epoch 243: validation loss 1.7210371405029297, accuracy 0.22776\n",
      "Epoch 244: validation loss 1.6686537854003907, accuracy 0.22856\n",
      "Epoch 245: validation loss 1.736281703491211, accuracy 0.23008\n",
      "Epoch 246: validation loss 1.8269244403076172, accuracy 0.22216\n",
      "Epoch 247: validation loss 1.8257891119384766, accuracy 0.23096\n",
      "Epoch 248: validation loss 1.7964703436279297, accuracy 0.23312\n",
      "Epoch 249: validation loss 1.8748222869873048, accuracy 0.2296\n",
      "Epoch 250: validation loss 1.903697091064453, accuracy 0.23304\n",
      "Epoch 251: validation loss 1.912355751953125, accuracy 0.22704\n",
      "Epoch 252: validation loss 1.826696615600586, accuracy 0.22272\n",
      "Epoch 253: validation loss 1.8522032257080079, accuracy 0.2208\n",
      "Epoch 254: validation loss 1.875691937866211, accuracy 0.2228\n",
      "Epoch 255: validation loss 1.9168308966064453, accuracy 0.22864\n",
      "Epoch 256: validation loss 1.8314148706054687, accuracy 0.22432\n",
      "Epoch 257: validation loss 2.017256362915039, accuracy 0.23288\n",
      "Epoch 258: validation loss 1.951576455078125, accuracy 0.22904\n",
      "Epoch 259: validation loss 1.8779194024658203, accuracy 0.21992\n",
      "Epoch 260: validation loss 1.7793652294921876, accuracy 0.22184\n",
      "Epoch 261: validation loss 1.9503103887939452, accuracy 0.22592\n",
      "Epoch 262: validation loss 1.9072997595214845, accuracy 0.22744\n",
      "Epoch 263: validation loss 2.045640101928711, accuracy 0.22384\n",
      "Epoch 264: validation loss 2.0393553143310545, accuracy 0.22656\n",
      "Epoch 265: validation loss 2.063272655029297, accuracy 0.2284\n",
      "Epoch 266: validation loss 2.028854948730469, accuracy 0.22352\n",
      "Epoch 267: validation loss 2.00873745513916, accuracy 0.22576\n",
      "Epoch 268: validation loss 2.0088402337646483, accuracy 0.2276\n",
      "Epoch 269: validation loss 2.0570094982910154, accuracy 0.226\n",
      "Epoch 270: validation loss 2.014558272705078, accuracy 0.2252\n",
      "Epoch 271: validation loss 2.2354146813964846, accuracy 0.2288\n",
      "Epoch 272: validation loss 2.1049957775878907, accuracy 0.22544\n",
      "Epoch 273: validation loss 2.1250359564208985, accuracy 0.2244\n",
      "Epoch 274: validation loss 2.052684771118164, accuracy 0.22664\n",
      "Epoch 275: validation loss 2.2455466613769532, accuracy 0.23\n",
      "Epoch 276: validation loss 2.2191556860351564, accuracy 0.22912\n",
      "Epoch 277: validation loss 2.209768737792969, accuracy 0.23392\n",
      "Epoch 278: validation loss 2.3157724798583983, accuracy 0.228\n",
      "Epoch 279: validation loss 2.3863755743408204, accuracy 0.23512\n",
      "Epoch 280: validation loss 2.438114926147461, accuracy 0.23192\n",
      "Epoch 281: validation loss 2.2870660217285157, accuracy 0.22848\n",
      "Epoch 282: validation loss 2.130909508666992, accuracy 0.22088\n",
      "Epoch 283: validation loss 2.2204079650878907, accuracy 0.22392\n",
      "Epoch 284: validation loss 2.11913314453125, accuracy 0.22496\n",
      "Epoch 285: validation loss 2.3603517657470703, accuracy 0.23648\n",
      "Epoch 286: validation loss 2.4280013787841797, accuracy 0.23272\n",
      "Epoch 287: validation loss 2.286275487060547, accuracy 0.22536\n",
      "Epoch 288: validation loss 2.362960115966797, accuracy 0.22784\n",
      "Epoch 289: validation loss 2.4164149084472655, accuracy 0.22704\n",
      "Epoch 290: validation loss 2.3922291369628907, accuracy 0.22952\n",
      "Epoch 291: validation loss 2.460462990722656, accuracy 0.22768\n",
      "Epoch 292: validation loss 2.381896201171875, accuracy 0.23432\n",
      "Epoch 293: validation loss 2.566560706176758, accuracy 0.22944\n",
      "Epoch 294: validation loss 2.4430742248535156, accuracy 0.2316\n",
      "Epoch 295: validation loss 2.2806339239501954, accuracy 0.22648\n",
      "Epoch 296: validation loss 2.42243130859375, accuracy 0.22848\n",
      "Epoch 297: validation loss 2.422058173828125, accuracy 0.22336\n",
      "Epoch 298: validation loss 2.394572318725586, accuracy 0.22896\n",
      "Epoch 299: validation loss 2.523713077392578, accuracy 0.23088\n",
      "Epoch 300: validation loss 2.590593983154297, accuracy 0.22872\n",
      "Epoch 301: validation loss 2.5456032415771483, accuracy 0.23248\n",
      "Epoch 302: validation loss 2.469251976928711, accuracy 0.23176\n",
      "Epoch 303: validation loss 2.592441509399414, accuracy 0.23752\n",
      "Epoch 304: validation loss 2.613905595703125, accuracy 0.2304\n",
      "Epoch 305: validation loss 2.5783086688232424, accuracy 0.22584\n",
      "Epoch 306: validation loss 2.589357944946289, accuracy 0.22192\n",
      "Epoch 307: validation loss 2.4884792633056643, accuracy 0.22352\n",
      "Epoch 308: validation loss 2.7393342443847657, accuracy 0.22888\n",
      "Epoch 309: validation loss 2.7065169665527344, accuracy 0.23016\n",
      "Epoch 310: validation loss 2.6820333984375, accuracy 0.22792\n",
      "Epoch 311: validation loss 2.704865327758789, accuracy 0.22632\n",
      "Epoch 312: validation loss 2.7685592449951173, accuracy 0.22856\n",
      "Epoch 313: validation loss 2.72384060546875, accuracy 0.23024\n",
      "Epoch 314: validation loss 2.955559063720703, accuracy 0.22552\n",
      "Epoch 315: validation loss 2.8219597735595703, accuracy 0.22864\n",
      "Epoch 316: validation loss 2.7617634173583983, accuracy 0.22928\n",
      "Epoch 317: validation loss 3.0729072595214846, accuracy 0.22976\n",
      "Epoch 318: validation loss 2.6644984802246094, accuracy 0.22456\n",
      "Epoch 319: validation loss 2.795195698852539, accuracy 0.22664\n",
      "Epoch 320: validation loss 2.8576349017333986, accuracy 0.22832\n",
      "Epoch 321: validation loss 2.810417548828125, accuracy 0.22664\n",
      "Epoch 322: validation loss 3.007661688232422, accuracy 0.22928\n",
      "Epoch 323: validation loss 2.7822500561523436, accuracy 0.22264\n",
      "Epoch 324: validation loss 2.863553645629883, accuracy 0.2252\n",
      "Epoch 325: validation loss 3.03564584777832, accuracy 0.22552\n",
      "Epoch 326: validation loss 2.9948534197998047, accuracy 0.23432\n",
      "Epoch 327: validation loss 2.9332614923095703, accuracy 0.22312\n",
      "Epoch 328: validation loss 3.157408592529297, accuracy 0.22272\n",
      "Epoch 329: validation loss 3.104502053222656, accuracy 0.22824\n",
      "Epoch 330: validation loss 3.1910819091796876, accuracy 0.22472\n",
      "Epoch 331: validation loss 3.14418817199707, accuracy 0.22864\n",
      "Epoch 332: validation loss 3.143531618652344, accuracy 0.232\n",
      "Epoch 333: validation loss 3.1138123205566406, accuracy 0.22872\n",
      "Epoch 334: validation loss 3.198549250488281, accuracy 0.22592\n",
      "Epoch 335: validation loss 3.2713115637207033, accuracy 0.22584\n",
      "Epoch 336: validation loss 3.0681563134765626, accuracy 0.22944\n",
      "Epoch 337: validation loss 3.251565360107422, accuracy 0.22224\n",
      "Epoch 338: validation loss 3.2737880700683593, accuracy 0.2252\n",
      "Epoch 339: validation loss 3.3957723547363283, accuracy 0.22104\n",
      "Epoch 340: validation loss 3.3145682641601564, accuracy 0.23024\n",
      "Epoch 341: validation loss 3.2599773583984377, accuracy 0.22008\n",
      "Epoch 342: validation loss 3.307609608154297, accuracy 0.23144\n",
      "Epoch 343: validation loss 3.3452993798828126, accuracy 0.22768\n",
      "Epoch 344: validation loss 3.361094486083984, accuracy 0.22864\n",
      "Epoch 345: validation loss 3.2355814770507814, accuracy 0.22496\n",
      "Epoch 346: validation loss 3.5561566674804688, accuracy 0.22872\n",
      "Epoch 347: validation loss 3.5572379357910155, accuracy 0.22824\n",
      "Epoch 348: validation loss 3.412927081298828, accuracy 0.2268\n",
      "Epoch 349: validation loss 3.442175203857422, accuracy 0.22704\n",
      "Epoch 350: validation loss 3.3885292700195313, accuracy 0.22504\n",
      "Epoch 351: validation loss 3.2597408404541017, accuracy 0.22872\n",
      "Epoch 352: validation loss 3.5408185888671877, accuracy 0.22936\n",
      "Epoch 353: validation loss 3.299330008544922, accuracy 0.23184\n",
      "Epoch 354: validation loss 3.538202947998047, accuracy 0.22824\n",
      "Epoch 355: validation loss 3.5743901171875, accuracy 0.2284\n",
      "Epoch 356: validation loss 3.419716690673828, accuracy 0.22696\n",
      "Epoch 357: validation loss 3.4258005859375, accuracy 0.22416\n",
      "Epoch 358: validation loss 3.475454832763672, accuracy 0.224\n",
      "Epoch 359: validation loss 3.5900943395996094, accuracy 0.23088\n",
      "Epoch 360: validation loss 3.664261015625, accuracy 0.22912\n",
      "Epoch 361: validation loss 3.945734030761719, accuracy 0.2388\n",
      "Epoch 362: validation loss 3.8194966345214842, accuracy 0.2264\n",
      "Epoch 363: validation loss 3.6852526538085937, accuracy 0.22592\n",
      "Epoch 364: validation loss 3.748523240966797, accuracy 0.23216\n",
      "Epoch 365: validation loss 3.703038171386719, accuracy 0.22808\n",
      "Epoch 366: validation loss 4.03748349975586, accuracy 0.23048\n",
      "Epoch 367: validation loss 3.768413681640625, accuracy 0.22624\n",
      "Epoch 368: validation loss 3.855376802978516, accuracy 0.22792\n",
      "Epoch 369: validation loss 3.878833310546875, accuracy 0.2292\n",
      "Epoch 370: validation loss 3.820699764404297, accuracy 0.23152\n",
      "Epoch 371: validation loss 3.762827989501953, accuracy 0.22744\n",
      "Epoch 372: validation loss 3.8906661669921876, accuracy 0.2288\n",
      "Epoch 373: validation loss 3.700428193359375, accuracy 0.228\n",
      "Epoch 374: validation loss 3.869946999511719, accuracy 0.22424\n",
      "Epoch 375: validation loss 3.8505725708007814, accuracy 0.22544\n",
      "Epoch 376: validation loss 4.0516599389648436, accuracy 0.22792\n",
      "Epoch 377: validation loss 3.945807325439453, accuracy 0.23336\n",
      "Epoch 378: validation loss 4.072280955810547, accuracy 0.232\n",
      "Epoch 379: validation loss 4.035204735107422, accuracy 0.22848\n",
      "Epoch 380: validation loss 3.850714729003906, accuracy 0.228\n",
      "Epoch 381: validation loss 3.972256953125, accuracy 0.22776\n",
      "Epoch 382: validation loss 3.8907684985351563, accuracy 0.224\n",
      "Epoch 383: validation loss 4.047382227783203, accuracy 0.22976\n",
      "Epoch 384: validation loss 4.130019196777344, accuracy 0.2252\n",
      "Epoch 385: validation loss 4.241462469482422, accuracy 0.22904\n",
      "Epoch 386: validation loss 4.082185404052734, accuracy 0.22728\n",
      "Epoch 387: validation loss 3.837716817626953, accuracy 0.2264\n",
      "Epoch 388: validation loss 3.844042449951172, accuracy 0.2284\n",
      "Epoch 389: validation loss 4.282370745849609, accuracy 0.2308\n",
      "Epoch 390: validation loss 4.280272110595703, accuracy 0.23176\n",
      "Epoch 391: validation loss 4.3094817138671875, accuracy 0.23096\n",
      "Epoch 392: validation loss 4.324629809570313, accuracy 0.23312\n",
      "Epoch 393: validation loss 4.516331134033203, accuracy 0.22888\n",
      "Epoch 394: validation loss 4.25750380859375, accuracy 0.22912\n",
      "Epoch 395: validation loss 4.441152989501953, accuracy 0.22704\n",
      "Epoch 396: validation loss 4.319055119628906, accuracy 0.22888\n",
      "Epoch 397: validation loss 4.274900083007813, accuracy 0.23264\n",
      "Epoch 398: validation loss 4.658406766357422, accuracy 0.23488\n",
      "Epoch 399: validation loss 4.426720780029297, accuracy 0.23296\n",
      "Epoch 400: validation loss 4.398719493408203, accuracy 0.23288\n",
      "Final test set performance:\n",
      "\tloss 4.43528918762207\n",
      "\taccuracy 0.2327\n"
     ]
    }
   ],
   "source": [
    "run_centralized(experiments[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from NPZ\n",
      "Epoch 1: validation loss 0.010139092280890641, accuracy 0.6296818364881193\n",
      "Epoch 2: validation loss 0.009425596344917473, accuracy 0.693717277486911\n",
      "Epoch 3: validation loss 0.008470487400163243, accuracy 0.7470801449859041\n",
      "Epoch 4: validation loss 0.008511355182023188, accuracy 0.7380185259766412\n",
      "Epoch 5: validation loss 0.008332371537694037, accuracy 0.7505034232782923\n",
      "Epoch 6: validation loss 0.008443343353713178, accuracy 0.7557390253725332\n",
      "Epoch 7: validation loss 0.008134617387312245, accuracy 0.7484897301651229\n",
      "Epoch 8: validation loss 0.00910601230504001, accuracy 0.7225130890052356\n",
      "Epoch 9: validation loss 0.009103907040420483, accuracy 0.738824003221909\n",
      "Epoch 10: validation loss 0.007724152119515934, accuracy 0.7720499395892066\n",
      "Epoch 11: validation loss 0.008195803493585407, accuracy 0.765807490938381\n",
      "Epoch 12: validation loss 0.007608979322283296, accuracy 0.7750704792589609\n",
      "Epoch 13: validation loss 0.007976552428759446, accuracy 0.7762786951268627\n",
      "Epoch 14: validation loss 0.008125824165881953, accuracy 0.7780910189287152\n",
      "Epoch 15: validation loss 0.010061403213611209, accuracy 0.7690293999194523\n",
      "Epoch 16: validation loss 0.007802612380399562, accuracy 0.7819170358437374\n",
      "Epoch 17: validation loss 0.008213043014848612, accuracy 0.7267418445428917\n",
      "Epoch 18: validation loss 0.008123930710196446, accuracy 0.7764800644381796\n",
      "Epoch 19: validation loss 0.007672709356235776, accuracy 0.7712444623439387\n",
      "Epoch 20: validation loss 0.008459172809839344, accuracy 0.7631896898912606\n",
      "Epoch 21: validation loss 0.008757198002133886, accuracy 0.7589609343536046\n",
      "Epoch 22: validation loss 0.00775899788784107, accuracy 0.7786951268626662\n",
      "Epoch 23: validation loss 0.00837008763094175, accuracy 0.7446637132501007\n",
      "Epoch 24: validation loss 0.007972994670001817, accuracy 0.7790978654853\n",
      "Epoch 25: validation loss 0.00793109471717286, accuracy 0.7760773258155457\n",
      "Epoch 26: validation loss 0.007862191477755217, accuracy 0.7776882803060814\n",
      "Epoch 27: validation loss 0.008815645061334294, accuracy 0.7410390656463954\n",
      "Epoch 28: validation loss 0.008843073514119493, accuracy 0.7704389850986709\n",
      "Epoch 29: validation loss 0.008663429903782428, accuracy 0.7464760370519533\n",
      "Epoch 30: validation loss 0.008821859325653979, accuracy 0.7730567861457914\n",
      "Epoch 31: validation loss 0.010703649718435935, accuracy 0.7533225936367297\n",
      "Epoch 32: validation loss 0.007530989261149784, accuracy 0.7750704792589609\n",
      "Epoch 33: validation loss 0.010581662463556121, accuracy 0.7539267015706806\n",
      "Epoch 34: validation loss 0.00887572273846072, accuracy 0.7660088602496979\n",
      "Epoch 35: validation loss 0.009170506847178413, accuracy 0.7492952074103907\n",
      "Epoch 36: validation loss 0.008797626658836008, accuracy 0.7682239226741845\n",
      "Epoch 37: validation loss 0.010053481917154678, accuracy 0.7374144180426903\n",
      "Epoch 38: validation loss 0.009190471612586161, accuracy 0.7718485702778897\n",
      "Epoch 39: validation loss 0.00939155588143303, accuracy 0.779299234796617\n",
      "Epoch 40: validation loss 0.0099841586546316, accuracy 0.779299234796617\n",
      "Epoch 41: validation loss 0.010218140738556763, accuracy 0.7738622633910592\n",
      "Epoch 42: validation loss 0.009878727502031668, accuracy 0.7579540877970198\n",
      "Epoch 43: validation loss 0.009953364999938577, accuracy 0.7754732178815948\n",
      "Epoch 44: validation loss 0.010912995105830594, accuracy 0.7776882803060814\n",
      "Epoch 45: validation loss 0.015527914667916884, accuracy 0.7112364075714861\n",
      "Epoch 46: validation loss 0.01017377619487933, accuracy 0.7664115988723319\n",
      "Epoch 47: validation loss 0.010375453233478821, accuracy 0.7648006443817962\n",
      "Epoch 48: validation loss 0.013128705685819487, accuracy 0.7406363270237616\n",
      "Epoch 49: validation loss 0.011080324241724218, accuracy 0.7623842126459928\n",
      "Epoch 50: validation loss 0.01745613038155805, accuracy 0.7511075312122433\n",
      "Epoch 51: validation loss 0.012616646155396921, accuracy 0.7599677809101892\n",
      "Epoch 52: validation loss 0.010948645020750708, accuracy 0.761377366089408\n",
      "Epoch 53: validation loss 0.016135951251307658, accuracy 0.7333870318163512\n",
      "Epoch 54: validation loss 0.016364729607292496, accuracy 0.756745871929118\n",
      "Epoch 55: validation loss 0.017001568634952693, accuracy 0.7660088602496979\n",
      "Epoch 56: validation loss 0.010907435400371729, accuracy 0.7688280306081353\n",
      "Epoch 57: validation loss 0.012332822183807962, accuracy 0.7593636729762384\n",
      "Epoch 58: validation loss 0.019431232601896293, accuracy 0.7599677809101892\n",
      "Epoch 59: validation loss 0.020216153170185804, accuracy 0.7124446234393879\n",
      "Epoch 60: validation loss 0.014477981838832399, accuracy 0.756745871929118\n",
      "Epoch 61: validation loss 0.012830099666305862, accuracy 0.7579540877970198\n",
      "Epoch 62: validation loss 0.017852272830852518, accuracy 0.7547321788159485\n",
      "Epoch 63: validation loss 0.011627315412689207, accuracy 0.7716472009665727\n",
      "Epoch 64: validation loss 0.016304951579734966, accuracy 0.7589609343536046\n",
      "Epoch 65: validation loss 0.012950743419169611, accuracy 0.7633910592025775\n",
      "Epoch 66: validation loss 0.015365889457219846, accuracy 0.7535239629480467\n",
      "Epoch 67: validation loss 0.012949207426317748, accuracy 0.7557390253725332\n",
      "Epoch 68: validation loss 0.030544031292884233, accuracy 0.7104309303262183\n",
      "Epoch 69: validation loss 0.016197345433722952, accuracy 0.765606121627064\n",
      "Epoch 70: validation loss 0.025536127667536525, accuracy 0.7132501006846557\n",
      "Epoch 71: validation loss 0.02283157076367053, accuracy 0.7452678211840515\n",
      "Epoch 72: validation loss 0.025544264673754615, accuracy 0.7660088602496979\n",
      "Epoch 73: validation loss 0.022584207178938547, accuracy 0.7410390656463954\n",
      "Epoch 74: validation loss 0.01847420160539007, accuracy 0.7585581957309706\n",
      "Epoch 75: validation loss 0.0099655873548394, accuracy 0.7666129681836488\n",
      "Epoch 76: validation loss 0.014037687440961299, accuracy 0.765807490938381\n",
      "Epoch 77: validation loss 0.03384716238074854, accuracy 0.7382198952879581\n",
      "Epoch 78: validation loss 0.01667880495853401, accuracy 0.7583568264196536\n",
      "Epoch 79: validation loss 0.025440719871332795, accuracy 0.7633910592025775\n",
      "Epoch 80: validation loss 0.021843744984231934, accuracy 0.7561417639951671\n",
      "Epoch 81: validation loss 0.036074866703139453, accuracy 0.7650020136931132\n",
      "Epoch 82: validation loss 0.022654675730427953, accuracy 0.7662102295610149\n",
      "Epoch 83: validation loss 0.027652547453566517, accuracy 0.7714458316552557\n",
      "Epoch 84: validation loss 0.031911355632714, accuracy 0.7692307692307693\n",
      "Epoch 85: validation loss 0.014370493593832393, accuracy 0.7700362464760371\n",
      "Epoch 86: validation loss 0.019662224821539304, accuracy 0.7408376963350786\n",
      "Epoch 87: validation loss 0.0507059267966247, accuracy 0.7581554571083367\n",
      "Epoch 88: validation loss 0.023778169621059695, accuracy 0.7676198147402336\n",
      "Epoch 89: validation loss 0.032874413497785, accuracy 0.7648006443817962\n",
      "Epoch 90: validation loss 0.02831451379383854, accuracy 0.7678211840515505\n",
      "Epoch 91: validation loss 0.03989661656893217, accuracy 0.7551349174385824\n",
      "Epoch 92: validation loss 0.029616651374680163, accuracy 0.7583568264196536\n",
      "Epoch 93: validation loss 0.04315938926300021, accuracy 0.7571486105517519\n",
      "Epoch 94: validation loss 0.01983750765776375, accuracy 0.7478856222311719\n",
      "Epoch 95: validation loss 0.03547887183032687, accuracy 0.7442609746274668\n",
      "Epoch 96: validation loss 0.015418223559592359, accuracy 0.7315747080144986\n",
      "Epoch 97: validation loss 0.04665360774093225, accuracy 0.7635924285138945\n",
      "Epoch 98: validation loss 0.03585476273737557, accuracy 0.761175996778091\n",
      "Epoch 99: validation loss 0.044544918194827275, accuracy 0.7597664115988724\n",
      "Epoch 100: validation loss 0.03510465113760433, accuracy 0.7573499798630688\n",
      "Epoch 101: validation loss 0.037851745167471834, accuracy 0.760974627466774\n",
      "Epoch 102: validation loss 0.02064792825073376, accuracy 0.7617801047120419\n",
      "Epoch 103: validation loss 0.03023941459624075, accuracy 0.7712444623439387\n",
      "Epoch 104: validation loss 0.025656826827154495, accuracy 0.7448650825614176\n",
      "Epoch 105: validation loss 0.02736905250777845, accuracy 0.7645992750704793\n",
      "Epoch 106: validation loss 0.04978146482944681, accuracy 0.756745871929118\n",
      "Epoch 107: validation loss 0.030727816189770923, accuracy 0.7462746677406363\n",
      "Epoch 108: validation loss 0.03886425460340321, accuracy 0.7637937978252114\n",
      "Epoch 109: validation loss 0.026360991959652497, accuracy 0.760974627466774\n",
      "Epoch 110: validation loss 0.04026430697629301, accuracy 0.7577527184857028\n",
      "Epoch 111: validation loss 0.033523816988922345, accuracy 0.7563431333064841\n",
      "Epoch 112: validation loss 0.030556327637481537, accuracy 0.7537253322593637\n",
      "Epoch 113: validation loss 0.06275160520056587, accuracy 0.7607732581554572\n",
      "Epoch 114: validation loss 0.045593065003017914, accuracy 0.7559403946838502\n",
      "Epoch 115: validation loss 0.07091013440863048, accuracy 0.7607732581554572\n",
      "Epoch 116: validation loss 0.07356906294870703, accuracy 0.7484897301651229\n",
      "Epoch 117: validation loss 0.036723770666304875, accuracy 0.752315747080145\n",
      "Epoch 118: validation loss 0.012054804269940057, accuracy 0.7589609343536046\n",
      "Epoch 119: validation loss 0.039686915017979496, accuracy 0.7597664115988724\n",
      "Epoch 120: validation loss 0.054059312995815775, accuracy 0.7597664115988724\n",
      "Epoch 121: validation loss 0.061182325447080986, accuracy 0.7549335481272654\n",
      "Epoch 122: validation loss 0.03614625529180935, accuracy 0.7329842931937173\n",
      "Epoch 123: validation loss 0.08068054343153284, accuracy 0.7553362867498993\n",
      "Epoch 124: validation loss 0.017507284429588963, accuracy 0.7311719693918647\n",
      "Epoch 125: validation loss 0.03344351523737729, accuracy 0.7440596053161498\n",
      "Epoch 126: validation loss 0.03518003377758876, accuracy 0.7728554168344745\n",
      "Epoch 127: validation loss 0.03945903202194002, accuracy 0.7573499798630688\n",
      "Epoch 128: validation loss 0.0557558979063422, accuracy 0.7619814740233588\n",
      "Epoch 129: validation loss 0.029765099929169307, accuracy 0.7450664518727346\n",
      "Epoch 130: validation loss 0.03296484385005322, accuracy 0.7535239629480467\n",
      "Epoch 131: validation loss 0.027915464639903746, accuracy 0.7325815545710833\n",
      "Epoch 132: validation loss 0.050482137641069444, accuracy 0.7513089005235603\n",
      "Epoch 133: validation loss 0.033024967748985334, accuracy 0.7501006846556585\n",
      "Epoch 134: validation loss 0.05941921599776429, accuracy 0.756947241240435\n",
      "Epoch 135: validation loss 0.06177552100203472, accuracy 0.7591623036649214\n",
      "Epoch 136: validation loss 0.0551665497495914, accuracy 0.7627869512686266\n",
      "Epoch 137: validation loss 0.0831901462650376, accuracy 0.7575513491743858\n",
      "Epoch 138: validation loss 0.058777114339667945, accuracy 0.7680225533628675\n",
      "Epoch 139: validation loss 0.06104232447069593, accuracy 0.7682239226741845\n",
      "Epoch 140: validation loss 0.059959212078762016, accuracy 0.7398308497784938\n",
      "Epoch 141: validation loss 0.03444088212890679, accuracy 0.7400322190898108\n",
      "Epoch 142: validation loss 0.05015834905522224, accuracy 0.7595650422875554\n",
      "Epoch 143: validation loss 0.051473190947208876, accuracy 0.7490938380990737\n",
      "Epoch 144: validation loss 0.05760261916341294, accuracy 0.7591623036649214\n",
      "Epoch 145: validation loss 0.05555310625128337, accuracy 0.7597664115988724\n",
      "Epoch 146: validation loss 0.02797281014141516, accuracy 0.7629883205799436\n",
      "Epoch 147: validation loss 0.06168856485879954, accuracy 0.765606121627064\n",
      "Epoch 148: validation loss 0.07314281695512241, accuracy 0.7507047925896093\n",
      "Epoch 149: validation loss 0.05101153434547166, accuracy 0.7595650422875554\n",
      "Epoch 150: validation loss 0.0904111986649022, accuracy 0.7829238824003222\n",
      "Epoch 151: validation loss 0.05302642705912942, accuracy 0.760974627466774\n",
      "Epoch 152: validation loss 0.09120852141624201, accuracy 0.7597664115988724\n",
      "Epoch 153: validation loss 0.08941943806071365, accuracy 0.7527184857027789\n",
      "Epoch 154: validation loss 0.08201890421691461, accuracy 0.7621828433346758\n",
      "Epoch 155: validation loss 0.08163782040222105, accuracy 0.7708417237213049\n",
      "Epoch 156: validation loss 0.16943502025262416, accuracy 0.7605718888441402\n",
      "Epoch 157: validation loss 0.1761105126831448, accuracy 0.747684252919855\n",
      "Epoch 158: validation loss 0.09725185541006234, accuracy 0.7686266612968183\n",
      "Epoch 159: validation loss 0.05135904862858622, accuracy 0.7597664115988724\n",
      "Epoch 160: validation loss 0.031193428836759903, accuracy 0.7549335481272654\n",
      "Epoch 161: validation loss 0.15850475844576434, accuracy 0.7496979460330245\n",
      "Epoch 162: validation loss 0.08159539704835564, accuracy 0.7571486105517519\n",
      "Epoch 163: validation loss 0.13471079381588627, accuracy 0.7555376560612163\n",
      "Epoch 164: validation loss 0.05191607891529066, accuracy 0.7641965364478454\n",
      "Epoch 165: validation loss 0.10197292680563678, accuracy 0.7621828433346758\n",
      "Epoch 166: validation loss 0.06975693493613398, accuracy 0.7639951671365284\n",
      "Epoch 167: validation loss 0.06065339333723977, accuracy 0.7599677809101892\n",
      "Epoch 168: validation loss 0.11228408322092318, accuracy 0.7603705195328232\n",
      "Epoch 169: validation loss 0.19177725612277038, accuracy 0.7654047523157471\n",
      "Epoch 170: validation loss 0.28286690508892015, accuracy 0.7629883205799436\n",
      "Epoch 171: validation loss 0.13778918162978468, accuracy 0.7573499798630688\n",
      "Epoch 172: validation loss 0.13206244097138142, accuracy 0.7643979057591623\n",
      "Epoch 173: validation loss 0.06366541309554491, accuracy 0.761578735400725\n",
      "Epoch 174: validation loss 0.06304678557334865, accuracy 0.7635924285138945\n",
      "Epoch 175: validation loss 0.11247609096623888, accuracy 0.7641965364478454\n",
      "Epoch 176: validation loss 0.159755541968144, accuracy 0.761175996778091\n",
      "Epoch 177: validation loss 0.030684259885556748, accuracy 0.7581554571083367\n",
      "Epoch 178: validation loss 0.04630270867975691, accuracy 0.765606121627064\n",
      "Epoch 179: validation loss 0.08740245383735439, accuracy 0.7607732581554572\n",
      "Epoch 180: validation loss 0.1045625324552692, accuracy 0.7561417639951671\n",
      "Epoch 181: validation loss 0.15335624771544495, accuracy 0.7382198952879581\n",
      "Epoch 182: validation loss 0.09990374181619154, accuracy 0.7464760370519533\n",
      "Epoch 183: validation loss 0.05721104403104794, accuracy 0.7507047925896093\n",
      "Epoch 184: validation loss 0.1700170996973604, accuracy 0.7557390253725332\n",
      "Epoch 185: validation loss 0.11968953670439487, accuracy 0.7641965364478454\n",
      "Epoch 186: validation loss 0.0682936952424251, accuracy 0.7716472009665727\n",
      "Epoch 187: validation loss 0.10842191438448319, accuracy 0.7551349174385824\n",
      "Epoch 188: validation loss 0.2756339779458985, accuracy 0.7728554168344745\n",
      "Epoch 189: validation loss 0.051883717950101924, accuracy 0.7492952074103907\n",
      "Epoch 190: validation loss 0.06778187128597817, accuracy 0.7533225936367297\n",
      "Epoch 191: validation loss 0.08948945951135323, accuracy 0.7501006846556585\n",
      "Epoch 192: validation loss 0.130497332558822, accuracy 0.7682239226741845\n",
      "Epoch 193: validation loss 0.1603798701116936, accuracy 0.7690293999194523\n",
      "Epoch 194: validation loss 0.09591392795260856, accuracy 0.7635924285138945\n",
      "Epoch 195: validation loss 0.17220711904910607, accuracy 0.7579540877970198\n",
      "Epoch 196: validation loss 0.159188978310991, accuracy 0.7509061619009263\n",
      "Epoch 197: validation loss 0.0963760777149669, accuracy 0.7605718888441402\n",
      "Epoch 198: validation loss 0.03531286108412188, accuracy 0.7152637937978252\n",
      "Epoch 199: validation loss 0.21845568993184722, accuracy 0.761175996778091\n",
      "Epoch 200: validation loss 0.11152788779450384, accuracy 0.7652033830044301\n",
      "Epoch 201: validation loss 0.09783834763894482, accuracy 0.7575513491743858\n",
      "Epoch 202: validation loss 0.3333809818416846, accuracy 0.7625855819573097\n",
      "Epoch 203: validation loss 0.21037377326468332, accuracy 0.7643979057591623\n",
      "Epoch 204: validation loss 0.08841966338038589, accuracy 0.7619814740233588\n",
      "Epoch 205: validation loss 0.15195451666643386, accuracy 0.7521143777688281\n",
      "Epoch 206: validation loss 0.39437884205154866, accuracy 0.7617801047120419\n",
      "Epoch 207: validation loss 0.1993651170669138, accuracy 0.7686266612968183\n",
      "Epoch 208: validation loss 0.1784679481592382, accuracy 0.7633910592025775\n",
      "Epoch 209: validation loss 0.3654528260471069, accuracy 0.7700362464760371\n",
      "Epoch 210: validation loss 0.0915628775108067, accuracy 0.7404349577124446\n",
      "Epoch 211: validation loss 0.1921105390707908, accuracy 0.7591623036649214\n",
      "Epoch 212: validation loss 0.1806520512398817, accuracy 0.7456705598066855\n",
      "Epoch 213: validation loss 0.09579710312490736, accuracy 0.7579540877970198\n",
      "Epoch 214: validation loss 0.2003214244059003, accuracy 0.7563431333064841\n",
      "Epoch 215: validation loss 0.14172588012125337, accuracy 0.7684252919855014\n",
      "Epoch 216: validation loss 0.09528678391568372, accuracy 0.7368103101087394\n",
      "Epoch 217: validation loss 0.34686824279689904, accuracy 0.7712444623439387\n",
      "Epoch 218: validation loss 0.24090072127344914, accuracy 0.7607732581554572\n",
      "Epoch 219: validation loss 0.2520615942191079, accuracy 0.7583568264196536\n",
      "Epoch 220: validation loss 0.12934215290624193, accuracy 0.7643979057591623\n",
      "Epoch 221: validation loss 0.22454131110464426, accuracy 0.7595650422875554\n",
      "Epoch 222: validation loss 0.16001029994955382, accuracy 0.7625855819573097\n",
      "Epoch 223: validation loss 0.08257186415211788, accuracy 0.7637937978252114\n",
      "Epoch 224: validation loss 0.35436481595087377, accuracy 0.7607732581554572\n",
      "Epoch 225: validation loss 0.2750254303180927, accuracy 0.7660088602496979\n",
      "Epoch 226: validation loss 0.23437844009779654, accuracy 0.765606121627064\n",
      "Epoch 227: validation loss 0.18099632392330992, accuracy 0.7545308095046315\n",
      "Epoch 228: validation loss 0.260406110491236, accuracy 0.7517116391461941\n",
      "Epoch 229: validation loss 0.28862606917376293, accuracy 0.7422472815142972\n",
      "Epoch 230: validation loss 0.16271061911440837, accuracy 0.743052758759565\n",
      "Epoch 231: validation loss 0.14049741773417146, accuracy 0.7549335481272654\n",
      "Epoch 232: validation loss 0.2763078198815083, accuracy 0.7547321788159485\n",
      "Epoch 233: validation loss 0.2482693155014462, accuracy 0.7577527184857028\n",
      "Epoch 234: validation loss 0.37712222894640923, accuracy 0.7505034232782923\n",
      "Epoch 235: validation loss 0.5579578115533927, accuracy 0.7710430930326219\n",
      "Epoch 236: validation loss 0.16330056145121097, accuracy 0.7511075312122433\n",
      "Epoch 237: validation loss 0.3333935788020558, accuracy 0.7571486105517519\n",
      "Epoch 238: validation loss 0.20572787336029932, accuracy 0.7531212243254128\n",
      "Epoch 239: validation loss 0.4582298708883832, accuracy 0.7742650020136931\n",
      "Epoch 240: validation loss 0.36261184677403635, accuracy 0.7639951671365284\n",
      "Epoch 241: validation loss 0.1870722143677901, accuracy 0.7533225936367297\n",
      "Epoch 242: validation loss 0.2820246067442723, accuracy 0.7577527184857028\n",
      "Epoch 243: validation loss 0.5330173037871209, accuracy 0.7680225533628675\n",
      "Epoch 244: validation loss 0.2958406614431488, accuracy 0.761377366089408\n",
      "Epoch 245: validation loss 0.3231758243174405, accuracy 0.7583568264196536\n",
      "Epoch 246: validation loss 0.17317833191821327, accuracy 0.7456705598066855\n",
      "Epoch 247: validation loss 0.2533456368452111, accuracy 0.7533225936367297\n",
      "Epoch 248: validation loss 0.2807818118166261, accuracy 0.7631896898912606\n",
      "Epoch 249: validation loss 0.49655768638938075, accuracy 0.7714458316552557\n",
      "Epoch 250: validation loss 0.2371045169910019, accuracy 0.7668143374949657\n",
      "Epoch 251: validation loss 0.16501057661688717, accuracy 0.7660088602496979\n",
      "Epoch 252: validation loss 0.2508203819112052, accuracy 0.7551349174385824\n",
      "Epoch 253: validation loss 0.36550733959583614, accuracy 0.7501006846556585\n",
      "Epoch 254: validation loss 0.2943621203633407, accuracy 0.760974627466774\n",
      "Epoch 255: validation loss 0.1663632682144666, accuracy 0.7712444623439387\n",
      "Epoch 256: validation loss 0.1509560020134135, accuracy 0.7462746677406363\n",
      "Epoch 257: validation loss 0.39621362434583857, accuracy 0.7668143374949657\n",
      "Epoch 258: validation loss 0.48740936084183484, accuracy 0.7780910189287152\n",
      "Epoch 259: validation loss 0.13127322217124726, accuracy 0.7676198147402336\n",
      "Epoch 260: validation loss 0.1849557823391629, accuracy 0.7414418042690294\n",
      "Epoch 261: validation loss 0.6036832098801482, accuracy 0.7678211840515505\n",
      "Epoch 262: validation loss 0.37113792484343366, accuracy 0.7742650020136931\n",
      "Epoch 263: validation loss 0.5509424324819171, accuracy 0.7621828433346758\n",
      "Epoch 264: validation loss 0.3853194869145529, accuracy 0.7637937978252114\n",
      "Epoch 265: validation loss 0.5432469741116115, accuracy 0.7621828433346758\n",
      "Epoch 266: validation loss 0.272200944439999, accuracy 0.7490938380990737\n",
      "Epoch 267: validation loss 0.45161741806334466, accuracy 0.7627869512686266\n",
      "Epoch 268: validation loss 0.4674056934052497, accuracy 0.7678211840515505\n",
      "Epoch 269: validation loss 0.6210399284700785, accuracy 0.7654047523157471\n",
      "Epoch 270: validation loss 0.1810230901296034, accuracy 0.7635924285138945\n",
      "Epoch 271: validation loss 0.17961402967770254, accuracy 0.7366089407974225\n",
      "Epoch 272: validation loss 0.6779440008148857, accuracy 0.7670157068062827\n",
      "Epoch 273: validation loss 0.33466998910500645, accuracy 0.7593636729762384\n",
      "Epoch 274: validation loss 0.46108923837440513, accuracy 0.7507047925896093\n",
      "Epoch 275: validation loss 0.3058322139243373, accuracy 0.7639951671365284\n",
      "Epoch 276: validation loss 0.24898291659172725, accuracy 0.7525171163914619\n",
      "Epoch 277: validation loss 0.6523620854737631, accuracy 0.7662102295610149\n",
      "Epoch 278: validation loss 0.5576681715919757, accuracy 0.7637937978252114\n",
      "Epoch 279: validation loss 0.2145273663610688, accuracy 0.7617801047120419\n",
      "Epoch 280: validation loss 0.15264874643920365, accuracy 0.7408376963350786\n",
      "Epoch 281: validation loss 0.48739218231751175, accuracy 0.7501006846556585\n",
      "Epoch 282: validation loss 0.15167713510956535, accuracy 0.7503020539669755\n",
      "Epoch 283: validation loss 0.3963478566944431, accuracy 0.7587595650422876\n",
      "Epoch 284: validation loss 0.3448400846470569, accuracy 0.7438582360048329\n",
      "Epoch 285: validation loss 0.35648253806118424, accuracy 0.7627869512686266\n",
      "Epoch 286: validation loss 0.39054586644428085, accuracy 0.7535239629480467\n",
      "Epoch 287: validation loss 0.43419614176187504, accuracy 0.7529198550140959\n",
      "Epoch 288: validation loss 0.8721530396660825, accuracy 0.765807490938381\n",
      "Epoch 289: validation loss 0.6923782243586527, accuracy 0.7680225533628675\n",
      "Epoch 290: validation loss 0.47414856700228913, accuracy 0.7706403544099879\n",
      "Epoch 291: validation loss 0.2564864874702282, accuracy 0.7515102698348771\n",
      "Epoch 292: validation loss 0.6847768178448963, accuracy 0.7555376560612163\n",
      "Epoch 293: validation loss 0.5931766809977402, accuracy 0.7623842126459928\n",
      "Epoch 294: validation loss 0.5418041432235109, accuracy 0.7619814740233588\n",
      "Epoch 295: validation loss 1.2250521781220822, accuracy 0.7599677809101892\n",
      "Epoch 296: validation loss 0.5032854159417001, accuracy 0.7694321385420861\n",
      "Epoch 297: validation loss 0.33049697314017346, accuracy 0.7625855819573097\n",
      "Epoch 298: validation loss 0.5676508295982536, accuracy 0.7629883205799436\n",
      "Epoch 299: validation loss 0.7681429561856193, accuracy 0.7686266612968183\n",
      "Epoch 300: validation loss 0.7291698232083085, accuracy 0.7573499798630688\n",
      "Epoch 301: validation loss 0.5958299975312625, accuracy 0.7601691502215062\n",
      "Epoch 302: validation loss 0.384665083150637, accuracy 0.7639951671365284\n",
      "Epoch 303: validation loss 0.5153058416124222, accuracy 0.7629883205799436\n",
      "Epoch 304: validation loss 0.773013910457966, accuracy 0.7730567861457914\n",
      "Epoch 305: validation loss 0.7275884916260988, accuracy 0.7684252919855014\n",
      "Epoch 306: validation loss 0.3435651955948306, accuracy 0.7724526782118405\n",
      "Epoch 307: validation loss 0.31782501617891384, accuracy 0.761377366089408\n",
      "Epoch 308: validation loss 0.6887457115823974, accuracy 0.7738622633910592\n",
      "Epoch 309: validation loss 0.4426639621602495, accuracy 0.7589609343536046\n",
      "Epoch 310: validation loss 0.6257298935146232, accuracy 0.7678211840515505\n",
      "Epoch 311: validation loss 0.45471695849264626, accuracy 0.7607732581554572\n",
      "Epoch 312: validation loss 0.5801767356156631, accuracy 0.7736608940797423\n",
      "Epoch 313: validation loss 0.5153708496835028, accuracy 0.7623842126459928\n",
      "Epoch 314: validation loss 0.3928049433101726, accuracy 0.7541280708819976\n",
      "Epoch 315: validation loss 0.39727742394467686, accuracy 0.7591623036649214\n",
      "Epoch 316: validation loss 0.5016736280663667, accuracy 0.7633910592025775\n",
      "Epoch 317: validation loss 0.36811169236598357, accuracy 0.7595650422875554\n",
      "Epoch 318: validation loss 0.47677835676874597, accuracy 0.7637937978252114\n",
      "Epoch 319: validation loss 0.2963718361207376, accuracy 0.7575513491743858\n",
      "Epoch 320: validation loss 0.5346183884398283, accuracy 0.7619814740233588\n",
      "Epoch 321: validation loss 0.5502108053675209, accuracy 0.7416431735803464\n",
      "Epoch 322: validation loss 1.5478286917921136, accuracy 0.7668143374949657\n",
      "Epoch 323: validation loss 1.000391470152094, accuracy 0.7617801047120419\n",
      "Epoch 324: validation loss 0.38065787370868426, accuracy 0.7662102295610149\n",
      "Epoch 325: validation loss 0.5425448253948844, accuracy 0.7650020136931132\n",
      "Epoch 326: validation loss 0.5987123906780432, accuracy 0.7682239226741845\n",
      "Epoch 327: validation loss 0.5091880048132692, accuracy 0.7623842126459928\n",
      "Epoch 328: validation loss 0.33756256434785903, accuracy 0.7549335481272654\n",
      "Epoch 329: validation loss 0.6799018707574974, accuracy 0.7633910592025775\n",
      "Epoch 330: validation loss 1.2603810527753887, accuracy 0.7666129681836488\n",
      "Epoch 331: validation loss 0.5944329582295781, accuracy 0.761578735400725\n",
      "Epoch 332: validation loss 0.6917354822206824, accuracy 0.7764800644381796\n",
      "Epoch 333: validation loss 0.6808027921546816, accuracy 0.7760773258155457\n",
      "Epoch 334: validation loss 0.7790418290054899, accuracy 0.7724526782118405\n",
      "Epoch 335: validation loss 0.7768664758530923, accuracy 0.7690293999194523\n",
      "Epoch 336: validation loss 0.7043836172482586, accuracy 0.7686266612968183\n",
      "Epoch 337: validation loss 1.2348218320888038, accuracy 0.7688280306081353\n",
      "Epoch 338: validation loss 0.6800697627347946, accuracy 0.7692307692307693\n",
      "Epoch 339: validation loss 0.7402384433830835, accuracy 0.7732581554571083\n",
      "Epoch 340: validation loss 0.46846139013311144, accuracy 0.7690293999194523\n",
      "Epoch 341: validation loss 0.5748414965440225, accuracy 0.7710430930326219\n",
      "Epoch 342: validation loss 0.8823118296257201, accuracy 0.7710430930326219\n",
      "Epoch 343: validation loss 0.6773107746076642, accuracy 0.7692307692307693\n",
      "Epoch 344: validation loss 1.2541116304662598, accuracy 0.7678211840515505\n",
      "Epoch 345: validation loss 1.0306714655553146, accuracy 0.7623842126459928\n",
      "Epoch 346: validation loss 0.8990120145518886, accuracy 0.7698348771647201\n",
      "Epoch 347: validation loss 0.7385000458562562, accuracy 0.7692307692307693\n",
      "Epoch 348: validation loss 0.776498323479728, accuracy 0.7680225533628675\n",
      "Epoch 349: validation loss 0.7026799287807542, accuracy 0.7730567861457914\n",
      "Epoch 350: validation loss 0.7252972594586486, accuracy 0.7660088602496979\n",
      "Epoch 351: validation loss 0.6416851670042046, accuracy 0.7712444623439387\n",
      "Epoch 352: validation loss 1.2575619809338512, accuracy 0.765807490938381\n",
      "Epoch 353: validation loss 0.8738145334702367, accuracy 0.7654047523157471\n",
      "Epoch 354: validation loss 0.6961603740795073, accuracy 0.7704389850986709\n",
      "Epoch 355: validation loss 0.7821156814412344, accuracy 0.7650020136931132\n",
      "Epoch 356: validation loss 0.7448769129431636, accuracy 0.7587595650422876\n",
      "Epoch 357: validation loss 1.0258193077505282, accuracy 0.7652033830044301\n",
      "Epoch 358: validation loss 0.7126902350964587, accuracy 0.7511075312122433\n",
      "Epoch 359: validation loss 0.3276728054135738, accuracy 0.7420459122029802\n",
      "Epoch 360: validation loss 0.2392709084302247, accuracy 0.7539267015706806\n",
      "Epoch 361: validation loss 0.6388707761797173, accuracy 0.7694321385420861\n",
      "Epoch 362: validation loss 0.5429305216740852, accuracy 0.760974627466774\n",
      "Epoch 363: validation loss 0.2572628218610105, accuracy 0.7438582360048329\n",
      "Epoch 364: validation loss 0.7731879164603176, accuracy 0.7742650020136931\n",
      "Epoch 365: validation loss 0.45469994248279966, accuracy 0.7599677809101892\n",
      "Epoch 366: validation loss 0.2606863751317338, accuracy 0.7444623439387837\n",
      "Epoch 367: validation loss 0.6881734986867917, accuracy 0.7645992750704793\n",
      "Epoch 368: validation loss 0.7264644724680347, accuracy 0.7605718888441402\n",
      "Epoch 369: validation loss 0.7997982648414707, accuracy 0.761377366089408\n",
      "Epoch 370: validation loss 0.5173535032038049, accuracy 0.7650020136931132\n",
      "Epoch 371: validation loss 1.485429226463954, accuracy 0.761578735400725\n",
      "Epoch 372: validation loss 1.0070295665132583, accuracy 0.7559403946838502\n",
      "Epoch 373: validation loss 0.6178122392067542, accuracy 0.7623842126459928\n",
      "Epoch 374: validation loss 1.3109445982866599, accuracy 0.756745871929118\n",
      "Epoch 375: validation loss 0.46622087760553504, accuracy 0.7660088602496979\n",
      "Epoch 376: validation loss 0.7762230347108322, accuracy 0.7639951671365284\n",
      "Epoch 377: validation loss 1.2317701140767472, accuracy 0.7617801047120419\n",
      "Epoch 378: validation loss 1.336967417466943, accuracy 0.7631896898912606\n",
      "Epoch 379: validation loss 0.505629327020672, accuracy 0.7617801047120419\n",
      "Epoch 380: validation loss 0.5426103685154725, accuracy 0.7529198550140959\n",
      "Epoch 381: validation loss 0.751694502870834, accuracy 0.7708417237213049\n",
      "Epoch 382: validation loss 0.47871876751949266, accuracy 0.7583568264196536\n",
      "Epoch 383: validation loss 0.7908822559225334, accuracy 0.7625855819573097\n",
      "Epoch 384: validation loss 0.6895442489074018, accuracy 0.765606121627064\n",
      "Epoch 385: validation loss 0.7021538785902953, accuracy 0.7704389850986709\n",
      "Epoch 386: validation loss 0.6155500976587082, accuracy 0.7686266612968183\n",
      "Epoch 387: validation loss 0.49509994233754007, accuracy 0.7462746677406363\n",
      "Epoch 388: validation loss 0.740539843643379, accuracy 0.7700362464760371\n",
      "Epoch 389: validation loss 0.6679408577148155, accuracy 0.765807490938381\n",
      "Epoch 390: validation loss 0.4980214145267101, accuracy 0.7623842126459928\n",
      "Epoch 391: validation loss 0.3643459421081789, accuracy 0.765606121627064\n",
      "Epoch 392: validation loss 0.5694432563950734, accuracy 0.7589609343536046\n",
      "Epoch 393: validation loss 1.0040524671311057, accuracy 0.7645992750704793\n",
      "Epoch 394: validation loss 0.46626160066069205, accuracy 0.7654047523157471\n",
      "Epoch 395: validation loss 0.7793665928942419, accuracy 0.761578735400725\n",
      "Epoch 396: validation loss 1.3898329156759617, accuracy 0.7648006443817962\n",
      "Epoch 397: validation loss 0.9220885646664899, accuracy 0.7650020136931132\n",
      "Epoch 398: validation loss 1.1922894223198217, accuracy 0.7674184454289167\n",
      "Epoch 399: validation loss 0.7826689005474193, accuracy 0.7593636729762384\n",
      "Epoch 400: validation loss 1.5662557979864888, accuracy 0.7619814740233588\n",
      "Final test set performance:\n",
      "\tloss 1.9991711696351282\n",
      "\taccuracy 0.7505635990180852\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_centralized(experiments[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority class count: 9266\n",
      "Epoch 1: validation loss 0.01593546709660141, accuracy 0.4782215796132297\n",
      "Epoch 2: validation loss 0.016530669125471284, accuracy 0.40683173685161755\n",
      "Epoch 3: validation loss 0.01581727283116859, accuracy 0.48093258630037955\n",
      "Epoch 4: validation loss 0.015543200257413538, accuracy 0.4590637990240376\n",
      "Epoch 5: validation loss 0.015726354773687064, accuracy 0.48436652810410263\n",
      "Epoch 6: validation loss 0.015897256565766203, accuracy 0.4742454364720766\n",
      "Epoch 7: validation loss 0.015633680625266072, accuracy 0.4832821254292427\n",
      "Epoch 8: validation loss 0.015335834868751855, accuracy 0.5107536598590277\n",
      "Epoch 9: validation loss 0.014758833758593597, accuracy 0.5338875835893728\n",
      "Epoch 10: validation loss 0.01551174245991544, accuracy 0.5156334718958974\n",
      "Epoch 11: validation loss 0.01624029322168656, accuracy 0.4431592264594253\n",
      "Epoch 12: validation loss 0.014197020284655124, accuracy 0.5553949033074281\n",
      "Epoch 13: validation loss 0.014759313191941821, accuracy 0.515994939454184\n",
      "Epoch 14: validation loss 0.014355170033022441, accuracy 0.547984818362552\n",
      "Epoch 15: validation loss 0.031580658215802505, accuracy 0.4196638351707934\n",
      "Epoch 16: validation loss 0.01444492714111615, accuracy 0.5387673956262425\n",
      "Epoch 17: validation loss 0.01419627225875165, accuracy 0.558105909994578\n",
      "Epoch 18: validation loss 0.014874951750681022, accuracy 0.510392192300741\n",
      "Epoch 19: validation loss 0.01400368927444232, accuracy 0.5609976504608711\n",
      "Epoch 20: validation loss 0.015240506929362766, accuracy 0.5009940357852882\n",
      "Epoch 21: validation loss 0.01939746860826121, accuracy 0.4343032712814025\n",
      "Epoch 22: validation loss 0.013863394666747936, accuracy 0.5651545273811676\n",
      "Epoch 23: validation loss 0.014194210840784014, accuracy 0.5644315922645943\n",
      "Epoch 24: validation loss 0.013778621618686954, accuracy 0.5714802096511838\n",
      "Epoch 25: validation loss 0.017247704685693102, accuracy 0.5150912705584674\n",
      "Epoch 26: validation loss 0.013984774123387809, accuracy 0.5532260979577083\n",
      "Epoch 27: validation loss 0.014113811758873197, accuracy 0.5107536598590277\n",
      "Epoch 28: validation loss 0.013395183753863869, accuracy 0.5830471715163564\n",
      "Epoch 29: validation loss 0.013732019803115952, accuracy 0.5875655159949394\n",
      "Epoch 30: validation loss 0.018483499646423825, accuracy 0.5387673956262425\n",
      "Epoch 31: validation loss 0.014965219607991808, accuracy 0.6157599855412976\n",
      "Epoch 32: validation loss 0.013765726525982186, accuracy 0.5718416772094704\n",
      "Epoch 33: validation loss 0.015006355969573627, accuracy 0.5635279233688777\n",
      "Epoch 34: validation loss 0.013690832142542913, accuracy 0.6081691668172782\n",
      "Epoch 35: validation loss 0.015190775713738752, accuracy 0.5913609253569492\n",
      "Epoch 36: validation loss 0.014532546507564609, accuracy 0.5295499728899331\n",
      "Epoch 37: validation loss 0.0203131964080441, accuracy 0.6114223748418579\n",
      "Epoch 38: validation loss 0.012963676795204531, accuracy 0.6099765046087113\n",
      "Epoch 39: validation loss 0.013514233749382064, accuracy 0.6043737574552683\n",
      "Epoch 40: validation loss 0.018013272226427728, accuracy 0.5956985360563889\n",
      "Epoch 41: validation loss 0.013148252030684076, accuracy 0.6278691487439002\n",
      "Epoch 42: validation loss 0.013303946828230282, accuracy 0.5888306524489427\n",
      "Epoch 43: validation loss 0.01322475767859537, accuracy 0.5877462497740827\n",
      "Epoch 44: validation loss 0.013180431213513349, accuracy 0.5922645942526659\n",
      "Epoch 45: validation loss 0.013893226085854507, accuracy 0.603650822338695\n",
      "Epoch 46: validation loss 0.013194558666990396, accuracy 0.6125067775167179\n",
      "Epoch 47: validation loss 0.01403370664969892, accuracy 0.5375022591722393\n",
      "Epoch 48: validation loss 0.014150841712693119, accuracy 0.569311404301464\n",
      "Epoch 49: validation loss 0.018039690021923044, accuracy 0.6296764865353335\n",
      "Epoch 50: validation loss 0.01371949633185178, accuracy 0.5909994577986626\n",
      "Epoch 51: validation loss 0.014065367003881585, accuracy 0.5628049882523044\n",
      "Epoch 52: validation loss 0.013736014466981182, accuracy 0.6233508042653172\n",
      "Epoch 53: validation loss 0.013638448267070936, accuracy 0.6007590818724019\n",
      "Epoch 54: validation loss 0.020447686484250844, accuracy 0.6336526296764865\n",
      "Epoch 55: validation loss 0.013961032536584388, accuracy 0.6247966744984638\n",
      "Epoch 56: validation loss 0.01351569698793255, accuracy 0.6258810771733236\n",
      "Epoch 57: validation loss 0.013884866623298483, accuracy 0.6009398156515453\n",
      "Epoch 58: validation loss 0.013442019495851153, accuracy 0.5967829387312489\n",
      "Epoch 59: validation loss 0.01323427612993098, accuracy 0.6226278691487439\n",
      "Epoch 60: validation loss 0.015280163904307614, accuracy 0.6358214350262064\n",
      "Epoch 61: validation loss 0.016202547688952153, accuracy 0.6280498825230436\n",
      "Epoch 62: validation loss 0.014686171538399332, accuracy 0.6331104283390566\n",
      "Epoch 63: validation loss 0.014729071413223209, accuracy 0.5546719681908548\n",
      "Epoch 64: validation loss 0.018378476973319385, accuracy 0.4386408819808422\n",
      "Epoch 65: validation loss 0.016858007072777594, accuracy 0.6329296945599132\n",
      "Epoch 66: validation loss 0.018124050911352343, accuracy 0.5956985360563889\n",
      "Epoch 67: validation loss 0.0475833867679081, accuracy 0.6320260256641966\n",
      "Epoch 68: validation loss 0.018092070417854038, accuracy 0.6379902403759262\n",
      "Epoch 69: validation loss 0.017545830389054197, accuracy 0.5980480751852522\n",
      "Epoch 70: validation loss 0.02497860324462499, accuracy 0.6278691487439002\n",
      "Epoch 71: validation loss 0.014997923468974664, accuracy 0.569311404301464\n",
      "Epoch 72: validation loss 0.017265269462441356, accuracy 0.5938911982649557\n",
      "Epoch 73: validation loss 0.02166093499971173, accuracy 0.6247966744984638\n",
      "Epoch 74: validation loss 0.017576440395853005, accuracy 0.5855774444243629\n",
      "Epoch 75: validation loss 0.017882190667632775, accuracy 0.6300379540936201\n",
      "Epoch 76: validation loss 0.016868420261684343, accuracy 0.6125067775167179\n",
      "Epoch 77: validation loss 0.014768793906955248, accuracy 0.5891921200072293\n",
      "Epoch 78: validation loss 0.01972469490862401, accuracy 0.6083499005964215\n",
      "Epoch 79: validation loss 0.013348081099842677, accuracy 0.6278691487439002\n",
      "Epoch 80: validation loss 0.01704743706509969, accuracy 0.5288270377733598\n",
      "Epoch 81: validation loss 0.022198548147610724, accuracy 0.6152177842038677\n",
      "Epoch 82: validation loss 0.018893396048612197, accuracy 0.6412434484005061\n",
      "Epoch 83: validation loss 0.015879431081985924, accuracy 0.5787095608169167\n",
      "Epoch 84: validation loss 0.019351418208369248, accuracy 0.5709380083137539\n",
      "Epoch 85: validation loss 0.02175903686579972, accuracy 0.5902765226820893\n",
      "Epoch 86: validation loss 0.01965619679409105, accuracy 0.6347370323513465\n",
      "Epoch 87: validation loss 0.024159503579893788, accuracy 0.6056388939092716\n",
      "Epoch 88: validation loss 0.024390495795141867, accuracy 0.6336526296764865\n",
      "Epoch 89: validation loss 0.016486082524303586, accuracy 0.6116031086210013\n",
      "Epoch 90: validation loss 0.022453143166608066, accuracy 0.5960600036146756\n",
      "Epoch 91: validation loss 0.020851004447942183, accuracy 0.6282306163021869\n",
      "Epoch 92: validation loss 0.01761163547890927, accuracy 0.6235315380444605\n",
      "Epoch 93: validation loss 0.03405760835399038, accuracy 0.6555214169528285\n",
      "Epoch 94: validation loss 0.023459977457714234, accuracy 0.6032893547804085\n",
      "Epoch 95: validation loss 0.01758187034344255, accuracy 0.5816013012832099\n",
      "Epoch 96: validation loss 0.035886152073291204, accuracy 0.6425085848545093\n",
      "Epoch 97: validation loss 0.028787158290925777, accuracy 0.5897343213446593\n",
      "Epoch 98: validation loss 0.04479101557165422, accuracy 0.6430507861919392\n",
      "Epoch 99: validation loss 0.04417872319013801, accuracy 0.6428700524127959\n",
      "Epoch 100: validation loss 0.038512621707130296, accuracy 0.6394361106090728\n",
      "Epoch 101: validation loss 0.018598523414438767, accuracy 0.543466473883969\n",
      "Epoch 102: validation loss 0.016599244834845435, accuracy 0.6018434845472619\n",
      "Epoch 103: validation loss 0.02007096083711893, accuracy 0.5190674136996205\n",
      "Epoch 104: validation loss 0.06330074609866436, accuracy 0.6600397614314115\n",
      "Epoch 105: validation loss 0.04250724581079502, accuracy 0.6340140972347732\n",
      "Epoch 106: validation loss 0.02985689463590425, accuracy 0.6313030905476233\n",
      "Epoch 107: validation loss 0.028106894067370953, accuracy 0.6497379360202422\n",
      "Epoch 108: validation loss 0.0487641560359133, accuracy 0.6528104102656787\n",
      "Epoch 109: validation loss 0.024304060151299926, accuracy 0.5969636725103922\n",
      "Epoch 110: validation loss 0.046315772051236395, accuracy 0.6397975781673595\n",
      "Epoch 111: validation loss 0.051300626448087146, accuracy 0.6186517260075908\n",
      "Epoch 112: validation loss 0.10042438756680588, accuracy 0.658051689860835\n",
      "Epoch 113: validation loss 0.06899212567129295, accuracy 0.6560636182902585\n",
      "Epoch 114: validation loss 0.08381373762071789, accuracy 0.6287728176396169\n",
      "Epoch 115: validation loss 0.06282223552901728, accuracy 0.6468461955539491\n",
      "Epoch 116: validation loss 0.03317875983205299, accuracy 0.6298572203144768\n",
      "Epoch 117: validation loss 0.04726122598977281, accuracy 0.6088921019338515\n",
      "Epoch 118: validation loss 0.026402539119310238, accuracy 0.532803180914513\n",
      "Epoch 119: validation loss 0.074001485263377, accuracy 0.6508223386951021\n",
      "Epoch 120: validation loss 0.07080751385478501, accuracy 0.6557021507319718\n",
      "Epoch 121: validation loss 0.0993352295067003, accuracy 0.6040122898969817\n",
      "Epoch 122: validation loss 0.09146647801908558, accuracy 0.6683535152720044\n",
      "Epoch 123: validation loss 0.09966283103731556, accuracy 0.6640159045725647\n",
      "Epoch 124: validation loss 0.029515734896098815, accuracy 0.594071932044099\n",
      "Epoch 125: validation loss 0.07619923596655334, accuracy 0.6096150370504247\n",
      "Epoch 126: validation loss 0.0679059048877925, accuracy 0.6510030724742454\n",
      "Epoch 127: validation loss 0.05939916619206561, accuracy 0.6343755647930598\n",
      "Epoch 128: validation loss 0.07391113194724697, accuracy 0.6571480209651184\n",
      "Epoch 129: validation loss 0.06327923825867414, accuracy 0.6412434484005061\n",
      "Epoch 130: validation loss 0.03890685290340573, accuracy 0.6146755828664378\n",
      "Epoch 131: validation loss 0.05509756370024248, accuracy 0.6432315199710826\n",
      "Epoch 132: validation loss 0.05195066110363451, accuracy 0.6332911621181999\n",
      "Epoch 133: validation loss 0.09963346737947469, accuracy 0.668714982830291\n",
      "Epoch 134: validation loss 0.049919842585676215, accuracy 0.6217242002530273\n",
      "Epoch 135: validation loss 0.04747349893165587, accuracy 0.6298572203144768\n",
      "Epoch 136: validation loss 0.19867296911979399, accuracy 0.6166636544370143\n",
      "Epoch 137: validation loss 0.3190899379383089, accuracy 0.6607626965479848\n",
      "Epoch 138: validation loss 0.04314945997175765, accuracy 0.6309416229893368\n",
      "Epoch 139: validation loss 0.028497862251374125, accuracy 0.6130489788541479\n",
      "Epoch 140: validation loss 0.0867438064913368, accuracy 0.6593168263148382\n",
      "Epoch 141: validation loss 0.1674929754375959, accuracy 0.6014820169889752\n",
      "Epoch 142: validation loss 0.04672143143899139, accuracy 0.6307608892101934\n",
      "Epoch 143: validation loss 0.05043860039184435, accuracy 0.6370865714802096\n",
      "Epoch 144: validation loss 0.049875784863965454, accuracy 0.6360021688053498\n",
      "Epoch 145: validation loss 0.06328800254373983, accuracy 0.6643773721308512\n",
      "Epoch 146: validation loss 0.08387583433321366, accuracy 0.6560636182902585\n",
      "Epoch 147: validation loss 0.050093468082720305, accuracy 0.5787095608169167\n",
      "Epoch 148: validation loss 0.10795966688103903, accuracy 0.6405205132839328\n",
      "Epoch 149: validation loss 0.08681271987238866, accuracy 0.6786553406831737\n",
      "Epoch 150: validation loss 0.06047631941026101, accuracy 0.6555214169528285\n",
      "Epoch 151: validation loss 0.07405274126125938, accuracy 0.6535333453822519\n",
      "Epoch 152: validation loss 0.04668531212305992, accuracy 0.6186517260075908\n",
      "Epoch 153: validation loss 0.08409630155640917, accuracy 0.6287728176396169\n",
      "Epoch 154: validation loss 0.10108599281647139, accuracy 0.6426893186336526\n",
      "Epoch 155: validation loss 0.13242106612845136, accuracy 0.6486535333453822\n",
      "Epoch 156: validation loss 0.041274559168192525, accuracy 0.5893728537863727\n",
      "Epoch 157: validation loss 0.0550097678036451, accuracy 0.626061810952467\n",
      "Epoch 158: validation loss 0.05592359830560552, accuracy 0.6613048978854148\n",
      "Epoch 159: validation loss 0.06569404384875716, accuracy 0.6457617928790891\n",
      "Epoch 160: validation loss 0.03844931205142456, accuracy 0.6069040303632749\n",
      "Epoch 161: validation loss 0.09267865550382301, accuracy 0.6661847099222845\n",
      "Epoch 162: validation loss 0.025252369360231737, accuracy 0.6079884330381349\n",
      "Epoch 163: validation loss 0.05535941884075132, accuracy 0.6450388577625158\n",
      "Epoch 164: validation loss 0.06748862388701501, accuracy 0.6602204952105548\n",
      "Epoch 165: validation loss 0.0855590147931602, accuracy 0.6376287728176396\n",
      "Epoch 166: validation loss 0.08475307310422549, accuracy 0.6594975600939815\n",
      "Epoch 167: validation loss 0.060844017145928006, accuracy 0.605277426350985\n",
      "Epoch 168: validation loss 0.1740454017264964, accuracy 0.6604012289896982\n",
      "Epoch 169: validation loss 0.08777275272676532, accuracy 0.6557021507319718\n",
      "Epoch 170: validation loss 0.11198363415311134, accuracy 0.6285920838604735\n",
      "Epoch 171: validation loss 0.1548226121836624, accuracy 0.6766672691125971\n",
      "Epoch 172: validation loss 0.15832455082179278, accuracy 0.6618470992228448\n",
      "Epoch 173: validation loss 0.10086693247511226, accuracy 0.6307608892101934\n",
      "Epoch 174: validation loss 0.10117594000661048, accuracy 0.6385324417133562\n",
      "Epoch 175: validation loss 0.1446527175331943, accuracy 0.6576902223025484\n",
      "Epoch 176: validation loss 0.10089616684592181, accuracy 0.6439544550876559\n",
      "Epoch 177: validation loss 0.13646821410794296, accuracy 0.6616663654437014\n",
      "Epoch 178: validation loss 0.06000223828551353, accuracy 0.5937104644858124\n",
      "Epoch 179: validation loss 0.09266996138052334, accuracy 0.6538948129405386\n",
      "Epoch 180: validation loss 0.07925708827588046, accuracy 0.6184709922284475\n",
      "Epoch 181: validation loss 0.07636490267611058, accuracy 0.63166455810591\n",
      "Epoch 182: validation loss 0.1047383197797868, accuracy 0.6757636002168805\n",
      "Epoch 183: validation loss 0.3968507450376263, accuracy 0.6407012470630761\n",
      "Epoch 184: validation loss 0.06988411541767627, accuracy 0.5908187240195193\n",
      "Epoch 185: validation loss 0.1280990887373368, accuracy 0.6347370323513465\n",
      "Epoch 186: validation loss 0.5492882882839901, accuracy 0.5967829387312489\n",
      "Epoch 187: validation loss 0.16458152131406908, accuracy 0.6258810771733236\n",
      "Epoch 188: validation loss 0.08965419625236268, accuracy 0.6511838062533888\n",
      "Epoch 189: validation loss 0.09615961175574202, accuracy 0.6320260256641966\n",
      "Epoch 190: validation loss 0.157796807224919, accuracy 0.6553406831736852\n",
      "Epoch 191: validation loss 0.09344695501208586, accuracy 0.6018434845472619\n",
      "Epoch 192: validation loss 0.04671604628375915, accuracy 0.6018434845472619\n",
      "Epoch 193: validation loss 0.13401110823366022, accuracy 0.6519067413699621\n",
      "Epoch 194: validation loss 0.1492304378471085, accuracy 0.6707030544008675\n",
      "Epoch 195: validation loss 0.13926878209013244, accuracy 0.6632929694559914\n",
      "Epoch 196: validation loss 0.1544838956633464, accuracy 0.6500994035785288\n",
      "Epoch 197: validation loss 0.16856037074093705, accuracy 0.6625700343394181\n",
      "Epoch 198: validation loss 0.2148030326053158, accuracy 0.668172781492861\n",
      "Epoch 199: validation loss 0.10932013969319694, accuracy 0.6484727995662389\n",
      "Epoch 200: validation loss 0.11258289879923507, accuracy 0.6497379360202422\n",
      "Epoch 201: validation loss 0.45579601812164455, accuracy 0.6294957527561902\n",
      "Epoch 202: validation loss 0.1277783569894474, accuracy 0.6403397795047895\n",
      "Epoch 203: validation loss 0.43941112816840083, accuracy 0.6575094885234051\n",
      "Epoch 204: validation loss 0.09403037687720818, accuracy 0.6173865895535876\n",
      "Epoch 205: validation loss 0.2118972274788719, accuracy 0.6594975600939815\n",
      "Epoch 206: validation loss 0.21224413815661577, accuracy 0.6670883788180011\n",
      "Epoch 207: validation loss 0.1741330188737949, accuracy 0.6699801192842942\n",
      "Epoch 208: validation loss 0.10833773748925941, accuracy 0.6652810410265678\n",
      "Epoch 209: validation loss 0.168430673953273, accuracy 0.6716067232965841\n",
      "Epoch 210: validation loss 0.0948723890500023, accuracy 0.6513645400325321\n",
      "Epoch 211: validation loss 0.10177577028820921, accuracy 0.6452195915416591\n",
      "Epoch 212: validation loss 0.08986391504957515, accuracy 0.6081691668172782\n",
      "Epoch 213: validation loss 0.1465079867880749, accuracy 0.6228086029278872\n",
      "Epoch 214: validation loss 0.07803381185257562, accuracy 0.6262425447316103\n",
      "Epoch 215: validation loss 0.09279834313869217, accuracy 0.6144948490872945\n",
      "Epoch 216: validation loss 0.11806528517205828, accuracy 0.6412434484005061\n",
      "Epoch 217: validation loss 0.14878296347955414, accuracy 0.6694379179468642\n",
      "Epoch 218: validation loss 0.47747368405788687, accuracy 0.6594975600939815\n",
      "Epoch 219: validation loss 0.23575530098722572, accuracy 0.6567865534068318\n",
      "Epoch 220: validation loss 0.06394704198742482, accuracy 0.5785288270377733\n",
      "Epoch 221: validation loss 0.08324191197766419, accuracy 0.6432315199710826\n",
      "Epoch 222: validation loss 0.1529207383446596, accuracy 0.6730525935297307\n",
      "Epoch 223: validation loss 0.09516748605532002, accuracy 0.658051689860835\n",
      "Epoch 224: validation loss 0.7254612455849792, accuracy 0.6649195734682812\n",
      "Epoch 225: validation loss 0.15833972094180937, accuracy 0.6710645219591541\n",
      "Epoch 226: validation loss 0.17946114922310977, accuracy 0.6663654437014278\n",
      "Epoch 227: validation loss 0.16637402806298418, accuracy 0.6622085667811314\n",
      "Epoch 228: validation loss 0.11361279423836233, accuracy 0.6412434484005061\n",
      "Epoch 229: validation loss 0.20963261247262932, accuracy 0.6416049159587927\n",
      "Epoch 230: validation loss 0.16042517889651256, accuracy 0.6604012289896982\n",
      "Epoch 231: validation loss 0.12408376614784174, accuracy 0.6332911621181999\n",
      "Epoch 232: validation loss 0.22692119271591907, accuracy 0.6676305801554311\n",
      "Epoch 233: validation loss 0.21253267471901918, accuracy 0.6497379360202422\n",
      "Epoch 234: validation loss 0.098334167849494, accuracy 0.6508223386951021\n",
      "Epoch 235: validation loss 0.12532277255253918, accuracy 0.6553406831736852\n",
      "Epoch 236: validation loss 0.09466877974503815, accuracy 0.6396168443882162\n",
      "Epoch 237: validation loss 0.15029257493921414, accuracy 0.6537140791613952\n",
      "Epoch 238: validation loss 0.35391187109827416, accuracy 0.6567865534068318\n",
      "Epoch 239: validation loss 0.20144799830533056, accuracy 0.6379902403759262\n",
      "Epoch 240: validation loss 0.2629679038396219, accuracy 0.6764865353334538\n",
      "Epoch 241: validation loss 0.10985058724352363, accuracy 0.6547984818362552\n",
      "Epoch 242: validation loss 0.14026643232133232, accuracy 0.6638351707934212\n",
      "Epoch 243: validation loss 0.14498828930254118, accuracy 0.6481113320079522\n",
      "Epoch 244: validation loss 0.2193554564516001, accuracy 0.6685342490511477\n",
      "Epoch 245: validation loss 0.16443562176911414, accuracy 0.6517260075908188\n",
      "Epoch 246: validation loss 0.16441516570925993, accuracy 0.6622085667811314\n",
      "Epoch 247: validation loss 0.17289215166875127, accuracy 0.6175673233327309\n",
      "Epoch 248: validation loss 0.09630680230735504, accuracy 0.6683535152720044\n",
      "Epoch 249: validation loss 0.3117102178487945, accuracy 0.6674498463762877\n",
      "Epoch 250: validation loss 0.21183894568447953, accuracy 0.6752213988794505\n",
      "Epoch 251: validation loss 0.14396622036370796, accuracy 0.6625700343394181\n",
      "Epoch 252: validation loss 0.18965476057573832, accuracy 0.6378095065967829\n",
      "Epoch 253: validation loss 0.0833095686357706, accuracy 0.6441351888667992\n",
      "Epoch 254: validation loss 0.1375217024723703, accuracy 0.6627507681185614\n",
      "Epoch 255: validation loss 0.16399660369877184, accuracy 0.6578709560816917\n",
      "Epoch 256: validation loss 0.18940714894163227, accuracy 0.6777516717874571\n",
      "Epoch 257: validation loss 0.208325222207305, accuracy 0.6596782938731249\n",
      "Epoch 258: validation loss 0.1511829865898768, accuracy 0.6750406651003072\n",
      "Epoch 259: validation loss 0.3326211218891664, accuracy 0.6725103921923007\n",
      "Epoch 260: validation loss 0.18102053065811038, accuracy 0.6714259895174408\n",
      "Epoch 261: validation loss 0.12543976207807614, accuracy 0.6537140791613952\n",
      "Epoch 262: validation loss 0.1825646235502027, accuracy 0.647388396891379\n",
      "Epoch 263: validation loss 0.07004864006216566, accuracy 0.6293150189770468\n",
      "Epoch 264: validation loss 0.15457548108170696, accuracy 0.6719681908548708\n",
      "Epoch 265: validation loss 0.1812773065521341, accuracy 0.679378275799747\n",
      "Epoch 266: validation loss 0.0819790214327087, accuracy 0.6491957346828122\n",
      "Epoch 267: validation loss 0.1570186913067321, accuracy 0.6524489427073921\n",
      "Epoch 268: validation loss 0.1377446956968902, accuracy 0.6623893005602747\n",
      "Epoch 269: validation loss 0.18389359390716237, accuracy 0.6853424905114766\n",
      "Epoch 270: validation loss 0.15705882586214268, accuracy 0.668714982830291\n",
      "Epoch 271: validation loss 0.08635401377814944, accuracy 0.6258810771733236\n",
      "Epoch 272: validation loss 0.11344961221192686, accuracy 0.6538948129405386\n",
      "Epoch 273: validation loss 0.08454075532689483, accuracy 0.6343755647930598\n",
      "Epoch 274: validation loss 0.1244977424788083, accuracy 0.6584131574191217\n",
      "Epoch 275: validation loss 0.12444234942519469, accuracy 0.6519067413699621\n",
      "Epoch 276: validation loss 0.35738506271678416, accuracy 0.6576902223025484\n",
      "Epoch 277: validation loss 0.10162480617978571, accuracy 0.6450388577625158\n",
      "Epoch 278: validation loss 0.18044776635770662, accuracy 0.6660039761431411\n",
      "Epoch 279: validation loss 0.20652911712824706, accuracy 0.668172781492861\n",
      "Epoch 280: validation loss 0.18681721815079608, accuracy 0.669799385505151\n",
      "Epoch 281: validation loss 0.1197664508030166, accuracy 0.6407012470630761\n",
      "Epoch 282: validation loss 0.12303406229593128, accuracy 0.6488342671245255\n",
      "Epoch 283: validation loss 0.30565800285244554, accuracy 0.6665461774805711\n",
      "Epoch 284: validation loss 0.2539123229301366, accuracy 0.6526296764865354\n",
      "Epoch 285: validation loss 0.1893623959796243, accuracy 0.6293150189770468\n",
      "Epoch 286: validation loss 0.1087457886897869, accuracy 0.6491957346828122\n",
      "Epoch 287: validation loss 0.22619886832881012, accuracy 0.6726911259714441\n",
      "Epoch 288: validation loss 0.09742494321485637, accuracy 0.6322067594433399\n",
      "Epoch 289: validation loss 0.1926403945056392, accuracy 0.6604012289896982\n",
      "Epoch 290: validation loss 0.1272473168829865, accuracy 0.6656425085848545\n",
      "Epoch 291: validation loss 0.29044204826448056, accuracy 0.679378275799747\n",
      "Epoch 292: validation loss 0.23032073894461433, accuracy 0.6524489427073921\n",
      "Epoch 293: validation loss 0.1364325474339714, accuracy 0.6416049159587927\n",
      "Epoch 294: validation loss 0.17468941684616382, accuracy 0.6555214169528285\n",
      "Epoch 295: validation loss 0.5120536601502491, accuracy 0.6562443520694018\n",
      "Epoch 296: validation loss 0.16657981975113487, accuracy 0.6506416049159588\n",
      "Epoch 297: validation loss 0.13016484687756225, accuracy 0.6510030724742454\n",
      "Epoch 298: validation loss 0.30661673313580734, accuracy 0.6533526116031086\n",
      "Epoch 299: validation loss 0.14451920865522722, accuracy 0.6622085667811314\n",
      "Epoch 300: validation loss 0.31262303984404344, accuracy 0.6676305801554311\n",
      "Epoch 301: validation loss 0.16352001709983724, accuracy 0.6730525935297307\n",
      "Epoch 302: validation loss 0.39268774512704796, accuracy 0.6269654798481836\n",
      "Epoch 303: validation loss 0.10985459751146041, accuracy 0.6358214350262064\n",
      "Epoch 304: validation loss 0.1647913399838031, accuracy 0.6598590276522682\n",
      "Epoch 305: validation loss 0.27357207803426287, accuracy 0.6773902042291704\n",
      "Epoch 306: validation loss 0.2174326393739151, accuracy 0.6614856316645581\n",
      "Epoch 307: validation loss 0.37719093152461075, accuracy 0.6651003072474245\n",
      "Epoch 308: validation loss 0.19069443750010892, accuracy 0.6717874570757274\n",
      "Epoch 309: validation loss 0.12663876247647313, accuracy 0.6468461955539491\n",
      "Epoch 310: validation loss 0.3675734190684039, accuracy 0.6726911259714441\n",
      "Epoch 311: validation loss 0.31554251185339094, accuracy 0.6607626965479848\n",
      "Epoch 312: validation loss 0.1704378504553174, accuracy 0.6412434484005061\n",
      "Epoch 313: validation loss 0.16588690628652952, accuracy 0.6495572022410988\n",
      "Epoch 314: validation loss 0.11292409579059691, accuracy 0.6638351707934212\n",
      "Epoch 315: validation loss 0.15972587365516375, accuracy 0.6609434303271281\n",
      "Epoch 316: validation loss 0.2666019456696385, accuracy 0.6848002891740467\n",
      "Epoch 317: validation loss 0.18341798317404395, accuracy 0.6578709560816917\n",
      "Epoch 318: validation loss 0.22237792693532313, accuracy 0.6589553587565516\n",
      "Epoch 319: validation loss 0.15426695247724606, accuracy 0.6538948129405386\n",
      "Epoch 320: validation loss 0.18659665521867835, accuracy 0.6598590276522682\n",
      "Epoch 321: validation loss 0.2502895898937899, accuracy 0.6786553406831737\n",
      "Epoch 322: validation loss 0.1242546879338158, accuracy 0.6605819627688415\n",
      "Epoch 323: validation loss 0.13955000932191222, accuracy 0.5971444062895355\n",
      "Epoch 324: validation loss 0.0852907044793175, accuracy 0.6419663835170794\n",
      "Epoch 325: validation loss 0.16005178338555343, accuracy 0.6564250858485451\n",
      "Epoch 326: validation loss 0.413898047650246, accuracy 0.6551599493945418\n",
      "Epoch 327: validation loss 0.20984774456303396, accuracy 0.6076269654798482\n",
      "Epoch 328: validation loss 0.23143478868754414, accuracy 0.6652810410265678\n",
      "Epoch 329: validation loss 0.15659960013670018, accuracy 0.6670883788180011\n",
      "Epoch 330: validation loss 0.22751457551580084, accuracy 0.6755828664377372\n",
      "Epoch 331: validation loss 0.18735003932440625, accuracy 0.6670883788180011\n",
      "Epoch 332: validation loss 0.17571836482674913, accuracy 0.6598590276522682\n",
      "Epoch 333: validation loss 0.08954433430260265, accuracy 0.6522682089282487\n",
      "Epoch 334: validation loss 0.13442214499884997, accuracy 0.6569672871859751\n",
      "Epoch 335: validation loss 0.6001021946056097, accuracy 0.6526296764865354\n",
      "Epoch 336: validation loss 0.2408531873411023, accuracy 0.6645581059099945\n",
      "Epoch 337: validation loss 0.8310925432684709, accuracy 0.614856316645581\n",
      "Epoch 338: validation loss 0.20014620140752373, accuracy 0.6815470811494668\n",
      "Epoch 339: validation loss 0.1389243908801476, accuracy 0.668172781492861\n",
      "Epoch 340: validation loss 0.1419972694094651, accuracy 0.6567865534068318\n",
      "Epoch 341: validation loss 0.1722257160136438, accuracy 0.6757636002168805\n",
      "Epoch 342: validation loss 0.2202250510211795, accuracy 0.6790168082414604\n",
      "Epoch 343: validation loss 0.23117859291810575, accuracy 0.6826314838243268\n",
      "Epoch 344: validation loss 0.09163592655878913, accuracy 0.6575094885234051\n",
      "Epoch 345: validation loss 0.14029834775926406, accuracy 0.6600397614314115\n",
      "Epoch 346: validation loss 0.04462116359910288, accuracy 0.6078076992589915\n",
      "Epoch 347: validation loss 0.2582295717758704, accuracy 0.6716067232965841\n",
      "Epoch 348: validation loss 0.0939265316355278, accuracy 0.6614856316645581\n",
      "Epoch 349: validation loss 0.21302648007966674, accuracy 0.6810048798120368\n",
      "Epoch 350: validation loss 0.11984222235396093, accuracy 0.6728718597505874\n",
      "Epoch 351: validation loss 0.11555639040226663, accuracy 0.6614856316645581\n",
      "Epoch 352: validation loss 0.10274295556530176, accuracy 0.6437737213085125\n",
      "Epoch 353: validation loss 2.4169057856066285, accuracy 0.589011386228086\n",
      "Epoch 354: validation loss 0.1278269941479738, accuracy 0.6670883788180011\n",
      "Epoch 355: validation loss 0.09168561304669127, accuracy 0.6546177480571119\n",
      "Epoch 356: validation loss 0.36538750001110004, accuracy 0.6699801192842942\n",
      "Epoch 357: validation loss 0.2464750787566761, accuracy 0.6643773721308512\n",
      "Epoch 358: validation loss 0.07876232065517605, accuracy 0.6078076992589915\n",
      "Epoch 359: validation loss 0.09946058422580197, accuracy 0.6267847460690403\n",
      "Epoch 360: validation loss 0.23851236366523276, accuracy 0.6835351527200434\n",
      "Epoch 361: validation loss 0.17370099138442247, accuracy 0.663112235676848\n",
      "Epoch 362: validation loss 0.2239640126839353, accuracy 0.6638351707934212\n",
      "Epoch 363: validation loss 0.09927395779552628, accuracy 0.6510030724742454\n",
      "Epoch 364: validation loss 0.1550966527197862, accuracy 0.6766672691125971\n",
      "Epoch 365: validation loss 0.1858403554838302, accuracy 0.6528104102656787\n",
      "Epoch 366: validation loss 0.11817345956598638, accuracy 0.6428700524127959\n",
      "Epoch 367: validation loss 0.17759784890755206, accuracy 0.6520874751491054\n",
      "Epoch 368: validation loss 0.1127299331808616, accuracy 0.6620278330019881\n",
      "Epoch 369: validation loss 0.10452968525278962, accuracy 0.6578709560816917\n",
      "Epoch 370: validation loss 0.04814162241190957, accuracy 0.5989517440809687\n",
      "Epoch 371: validation loss 0.10322344741574813, accuracy 0.6396168443882162\n",
      "Epoch 372: validation loss 0.1335832097313621, accuracy 0.6305801554310501\n",
      "Epoch 373: validation loss 0.0887151429887148, accuracy 0.6446773902042292\n",
      "Epoch 374: validation loss 0.11939419908073697, accuracy 0.6560636182902585\n",
      "Epoch 375: validation loss 0.09123022265876371, accuracy 0.6515452738116754\n",
      "Epoch 376: validation loss 0.05039625025217817, accuracy 0.6387131754924995\n",
      "Epoch 377: validation loss 0.2048014102265651, accuracy 0.6604012289896982\n",
      "Epoch 378: validation loss 0.07538999046961352, accuracy 0.6307608892101934\n",
      "Epoch 379: validation loss 0.05529520366412917, accuracy 0.6345562985722032\n",
      "Epoch 380: validation loss 0.0746914224708229, accuracy 0.6593168263148382\n",
      "Epoch 381: validation loss 0.07161543661445384, accuracy 0.6191939273450208\n",
      "Epoch 382: validation loss 0.11367375713219463, accuracy 0.6605819627688415\n",
      "Epoch 383: validation loss 0.09710506552191726, accuracy 0.6264232785107536\n",
      "Epoch 384: validation loss 0.10194500313946207, accuracy 0.6651003072474245\n",
      "Epoch 385: validation loss 0.07495007722002461, accuracy 0.6385324417133562\n",
      "Epoch 386: validation loss 0.05000896976758101, accuracy 0.6336526296764865\n",
      "Epoch 387: validation loss 0.09301935842191034, accuracy 0.6688957166094343\n",
      "Epoch 388: validation loss 0.2455685832671526, accuracy 0.6549792156153985\n",
      "Epoch 389: validation loss 0.07060367683379275, accuracy 0.6522682089282487\n",
      "Epoch 390: validation loss 0.0459436349275852, accuracy 0.6407012470630761\n",
      "Epoch 391: validation loss 0.15690552406235198, accuracy 0.6381709741550696\n",
      "Epoch 392: validation loss 0.09092196925044513, accuracy 0.6482920657870956\n",
      "Epoch 393: validation loss 0.037787066129928853, accuracy 0.6293150189770468\n",
      "Epoch 394: validation loss 0.05702451799524729, accuracy 0.6358214350262064\n",
      "Epoch 395: validation loss 0.11915100978163252, accuracy 0.6672691125971444\n",
      "Epoch 396: validation loss 0.0976985860814588, accuracy 0.6685342490511477\n",
      "Epoch 397: validation loss 0.08236671269704825, accuracy 0.6598590276522682\n",
      "Epoch 398: validation loss 0.20253167461793073, accuracy 0.6763058015543105\n",
      "Epoch 399: validation loss 0.0628438747943945, accuracy 0.6264232785107536\n",
      "Epoch 400: validation loss 0.14047233501007214, accuracy 0.6649195734682812\n",
      "Final test set performance:\n",
      "\tloss 0.14501426799678213\n",
      "\taccuracy 0.6670785525154457\n"
     ]
    }
   ],
   "source": [
    "run_centralized(experiments[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a FLWR environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.1.0a0+cxx11.abi and Flower 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "import flwr.server.strategy as strategy\n",
    "\n",
    "from flwr.common import Metrics\n",
    "\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "fl.common.logger.configure(identifier=\"FL Paper Experiment\", filename=f\"log_FLWR_{today.timestamp()}.txt\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")\n",
    "\n",
    "NUM_CLIENTS = 20\n",
    "TRAINING_ROUNDS = 50\n",
    "\n",
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll set up the Client configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from logging import DEBUG, INFO\n",
    "from flwr.common.logger import log\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader, cid):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.cid = cid\n",
    "        self.round = 0\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        # Return the current local parameters\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        # Train the local model after updating it with the given parameters\n",
    "        # Return the parameters from the newly trained model, the length\n",
    "        # of the training data, and a dict (empty in this case)\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs = 1)\n",
    "        self.round+=1\n",
    "        log(DEBUG, f\"Client {self.cid} in round {self.round}\")\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        # Perform the evaluation of the model after updating it with the given\n",
    "        # parameters. Returns the loss as a float, the length of the validation\n",
    "        # data, and a dict containing the accuracy\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return loss, len(self.valloader), {'accuracy': float(accuracy)}\n",
    "\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, setting up the strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FedAvg on CIFAR ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "fedAvg = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,  \n",
    "    fraction_evaluate=0.5,  \n",
    "    min_fit_clients=1,  \n",
    "    min_evaluate_clients=1, \n",
    "    min_available_clients=1,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "\n",
    "# A couple of client_fns for using with Flower, one for each dataset experiment\n",
    "def client_fn_CIFAR10_IID(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Create model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    trainloaders, valloaders,_ =  DATA_STORE[\"CIFAR10_IID\"]\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader, cid).to_client()\n",
    "\n",
    "def client_fn_CIFAR10_nonIID(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Create model\n",
    "    net = Net().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    trainloaders, valloaders,_ =  DATA_STORE[\"CIFAR10_NonIID\"]\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, valloader, cid).to_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick run to check if Flower is working ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start simulation\n",
    "run = False\n",
    "if (run):\n",
    "    fl.simulation.start_simulation(\n",
    "        client_fn=client_fn_CIFAR10_IID,\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=2),\n",
    "        strategy=fedAvg,\n",
    "        client_resources=client_resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FedExperiment Class ###\n",
    "Ok, so now i'll encapsulate this code to reuse with different strategies and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedExperiment():\n",
    "\n",
    "    def __init__(self, client_fn,strategy, name=\"New experiment\"):\n",
    "        self.client_fn = client_fn\n",
    "        self.strategy = strategy\n",
    "        self.name = name\n",
    "\n",
    "    def simulate_FL(self, rounds=1):\n",
    "        log(INFO, \"\\n\" + 10 * \"========\" + \"\\n\" + self.name + \" has started\\n\" + 10 * \"========\"  )\n",
    "        metrics = fl.simulation.start_simulation(\n",
    "                            client_fn=self.client_fn,\n",
    "                            num_clients=NUM_CLIENTS,\n",
    "                            config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "                            strategy=self.strategy,\n",
    "                            client_resources=client_resources,\n",
    "                        )\n",
    "        log(INFO, \"\\n\" + 10 * \"========\" + \"\\n\" + self.name + \" has ended\\n\" + 10 * \"========\"  )\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DATA_STORE[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10_IID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[43mpartition_scripts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition_CIFAR_IID\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNUM_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCIFAR10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m exp_CIFAR10_IID \u001b[38;5;241m=\u001b[39m FedExperiment(client_fn\u001b[38;5;241m=\u001b[39mclient_fn_CIFAR10_IID, strategy\u001b[38;5;241m=\u001b[39mfedAvg, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR 10 - IID Distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m exp_CIFAR10_IID\u001b[38;5;241m.\u001b[39msimulate_FL(rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\leon1\\Documents\\Research Repo\\Experiments\\Ethnicity FL paper\\partition_scripts.py:17\u001b[0m, in \u001b[0;36mpartition_CIFAR_IID\u001b[1;34m(num_clients, CIFAR_TYPE)\u001b[0m\n\u001b[0;32m     15\u001b[0m trainset, testset \u001b[38;5;241m=\u001b[39m load_CIFAR(CIFAR_TYPE)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#returns a tuple of (trainloaders, valloaders, testloaders)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIID_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leon1\\Documents\\Research Repo\\Experiments\\Ethnicity FL paper\\partition_scripts.py:54\u001b[0m, in \u001b[0;36mIID_setup\u001b[1;34m(num_clients, trainset, testset)\u001b[0m\n\u001b[0;32m     52\u001b[0m partition_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m num_clients\n\u001b[0;32m     53\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [partition_size] \u001b[38;5;241m*\u001b[39m num_clients\n\u001b[1;32m---> 54\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Split each partition into train/val and create DataLoader\u001b[39;00m\n\u001b[0;32m     56\u001b[0m trainloaders, valloaders, testloader \u001b[38;5;241m=\u001b[39m make_loaders(num_clients, testset, datasets)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataset.py:419\u001b[0m, in \u001b[0;36mrandom_split\u001b[1;34m(dataset, lengths, generator)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Cannot verify that dataset is Sized\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset):    \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of input lengths does not equal the length of the input dataset!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    421\u001b[0m indices \u001b[38;5;241m=\u001b[39m randperm(\u001b[38;5;28msum\u001b[39m(lengths), generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# type: ignore[arg-type, call-overload]\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [Subset(dataset, indices[offset \u001b[38;5;241m-\u001b[39m length : offset]) \u001b[38;5;28;01mfor\u001b[39;00m offset, length \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(_accumulate(lengths), lengths)]\n",
      "\u001b[1;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "DATA_STORE[\"CIFAR10_IID\"]= partition_scripts.partition_CIFAR_IID(NUM_CLIENTS, \"CIFAR10\")\n",
    "exp_CIFAR10_IID = FedExperiment(client_fn=client_fn_CIFAR10_IID, strategy=fedAvg, name=\"CIFAR 10 - IID Distribution\")\n",
    "metrics = exp_CIFAR10_IID.simulate_FL(rounds=5)\n",
    "print(metrics)\n",
    "DATA_STORE[\"CIFAR10_IID\"]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape CIFAR nonIID: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-02-23 14:24:39,699 | 527930960.py:9 | \n",
      "================================================================================\n",
      "CIFAR 10 - nonIID Distribution has started\n",
      "================================================================================\n",
      "INFO flwr 2024-02-23 14:24:39,699 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "2024-02-23 14:24:45,001\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-02-23 14:24:46,803 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 5832088782.0, 'object_store_memory': 2916044390.0, 'node:127.0.0.1': 1.0, 'CPU': 12.0, 'node:__internal_head__': 1.0}\n",
      "INFO flwr 2024-02-23 14:24:46,818 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-02-23 14:24:46,819 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0}\n",
      "INFO flwr 2024-02-23 14:24:46,819 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 12 actors\n",
      "INFO flwr 2024-02-23 14:24:46,819 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-02-23 14:24:46,819 | server.py:276 | Requesting initial parameters from one random client\n",
      "INFO flwr 2024-02-23 14:24:52,607 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-02-23 14:24:52,607 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-02-23 14:24:52,617 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-02-23 14:24:52,618 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=9840)\u001b[0m DEBUG flwr 2024-02-23 14:26:17,561 | 3002787810.py:26 | Client 7 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=7540)\u001b[0m DEBUG flwr 2024-02-23 14:26:55,225 | 3002787810.py:26 | Client 0 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=13024)\u001b[0m DEBUG flwr 2024-02-23 14:27:21,229 | 3002787810.py:26 | Client 2 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=4828)\u001b[0m DEBUG flwr 2024-02-23 14:27:26,333 | 3002787810.py:26 | Client 6 in round 1\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=5996)\u001b[0m DEBUG flwr 2024-02-23 14:27:32,839 | 3002787810.py:26 | Client 1 in round 1\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=1160)\u001b[0m DEBUG flwr 2024-02-23 14:27:35,274 | 3002787810.py:26 | Client 3 in round 1\n",
      "DEBUG flwr 2024-02-23 14:27:45,649 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=16952)\u001b[0m DEBUG flwr 2024-02-23 14:27:45,616 | 3002787810.py:26 | Client 8 in round 1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "WARNING flwr 2024-02-23 14:27:45,755 | fedavg.py:250 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flwr 2024-02-23 14:27:45,755 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
      "DEBUG flwr 2024-02-23 14:28:08,633 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
      "DEBUG flwr 2024-02-23 14:28:08,633 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2024-02-23 14:29:26,537 C 7588 12368] (raylet.exe) dlmalloc.cc:129:  Check failed: *handle != nullptr CreateFileMapping() failed. GetLastError() = 1450\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m unknown\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m recalloc\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m BaseThreadInitThunk\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m RtlUserThreadStart\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "2024-02-23 14:29:41,188\tWARNING worker.py:2037 -- The node with node id: c1287d6e1710f87a8e1158cd3b0b2595374734f26eac2826539b9c86 and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, preempted node, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n",
      "Exception in thread Thread-52:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py\", line 1358, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flwr\\simulation\\app.py\", line 276, in update_resources\n",
      "    num_max_actors = pool_size_from_resources(client_resources)\n",
      "  File \"c:\\Users\\leon1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 155, in pool_size_from_resources\n",
      "    num_cpus,\n",
      "UnboundLocalError: local variable 'num_cpus' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "DATA_STORE[\"CIFAR10_NonIID\"] = partition_scripts.partition_CIFAR_nonIID(NUM_CLIENTS)\n",
    "exp_CIFAR10_nonIID = FedExperiment(client_fn=client_fn_CIFAR10_nonIID, strategy=fedAvg, name=\"CIFAR 10 - nonIID Distribution\")\n",
    "metrics = exp_CIFAR10_nonIID.simulate_FL(rounds=5)\n",
    "print(metrics)\n",
    "DATA_STORE[\"CIFAR10_NonIID\"] = partition_scripts.partition_CIFAR_nonIID(NUM_CLIENTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
